[WARN] 2018-10-24 01:20:50,601 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 01:20:51,544 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 01:20:51,571 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_TO_EDW_INVOICE
[INFO] 2018-10-24 01:20:51,784 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 01:20:51,784 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 01:20:51,785 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 01:20:51,785 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 01:20:51,785 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 01:20:52,077 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 11989.
[INFO] 2018-10-24 01:20:52,113 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 01:20:52,138 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 01:20:52,141 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 01:20:52,142 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 01:20:52,153 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-10312ea4-22a5-46e4-89e7-065486422979
[INFO] 2018-10-24 01:20:52,179 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 01:20:52,198 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 01:20:52,432 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 01:20:52,497 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 01:20:52,596 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540369252596
[INFO] 2018-10-24 01:20:52,599 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-11cc9cb1-dc3f-4585-97ae-a1c3e56af66d/userFiles-3a2624fc-8777-4ead-89ad-59d139f2c5db/etl_config.json
[INFO] 2018-10-24 01:20:52,613 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py with timestamp 1540369252613
[INFO] 2018-10-24 01:20:52,614 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py to /tmp/spark-11cc9cb1-dc3f-4585-97ae-a1c3e56af66d/userFiles-3a2624fc-8777-4ead-89ad-59d139f2c5db/JB_WORK_TO_EDW_INVOICE.py
[INFO] 2018-10-24 01:20:52,617 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540369252617
[INFO] 2018-10-24 01:20:52,618 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-11cc9cb1-dc3f-4585-97ae-a1c3e56af66d/userFiles-3a2624fc-8777-4ead-89ad-59d139f2c5db/packages.zip
[INFO] 2018-10-24 01:20:52,682 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 01:20:52,705 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 27240.
[INFO] 2018-10-24 01:20:52,706 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:27240
[INFO] 2018-10-24 01:20:52,708 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 01:20:52,742 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 27240, None)
[INFO] 2018-10-24 01:20:52,748 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:27240 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 27240, None)
[INFO] 2018-10-24 01:20:52,751 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 27240, None)
[INFO] 2018-10-24 01:20:52,752 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 27240, None)
[INFO] 2018-10-24 01:20:53,033 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 01:20:53,033 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 01:20:53,650 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 01:20:54,648 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 01:20:54,658 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 01:20:54,672 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 01:20:54,681 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 01:20:54,682 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 01:20:54,688 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 01:20:54,693 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 01:20:54,703 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 01:20:54,704 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 01:20:54,705 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-11cc9cb1-dc3f-4585-97ae-a1c3e56af66d
[INFO] 2018-10-24 01:20:54,705 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-11cc9cb1-dc3f-4585-97ae-a1c3e56af66d/pyspark-b6dc4dd9-009a-4330-8241-3e08729ff709
[INFO] 2018-10-24 01:20:54,706 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-84287ba7-4abb-4d0e-af6b-1c1b2cd05fe6
[WARN] 2018-10-24 01:21:12,298 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 01:21:13,098 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 01:21:13,124 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_TO_EDW_INVOICE
[INFO] 2018-10-24 01:21:13,361 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 01:21:13,361 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 01:21:13,361 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 01:21:13,362 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 01:21:13,362 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 01:21:13,569 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 9410.
[INFO] 2018-10-24 01:21:13,595 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 01:21:13,616 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 01:21:13,619 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 01:21:13,620 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 01:21:13,629 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-681f3dfa-57c5-47fd-a703-16be61b73986
[INFO] 2018-10-24 01:21:13,648 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 01:21:13,662 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 01:21:13,865 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 01:21:13,933 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 01:21:14,052 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540369274052
[INFO] 2018-10-24 01:21:14,054 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-662c8528-8d2f-4f28-a2f7-56444c42a01a/userFiles-e83d0fdf-8384-4e63-9fbc-b730e71ecf53/etl_config.json
[INFO] 2018-10-24 01:21:14,069 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py with timestamp 1540369274068
[INFO] 2018-10-24 01:21:14,069 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py to /tmp/spark-662c8528-8d2f-4f28-a2f7-56444c42a01a/userFiles-e83d0fdf-8384-4e63-9fbc-b730e71ecf53/JB_WORK_TO_EDW_INVOICE.py
[INFO] 2018-10-24 01:21:14,077 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540369274076
[INFO] 2018-10-24 01:21:14,077 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-662c8528-8d2f-4f28-a2f7-56444c42a01a/userFiles-e83d0fdf-8384-4e63-9fbc-b730e71ecf53/packages.zip
[INFO] 2018-10-24 01:21:14,152 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 01:21:14,176 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 20612.
[INFO] 2018-10-24 01:21:14,177 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:20612
[INFO] 2018-10-24 01:21:14,179 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 01:21:14,213 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 20612, None)
[INFO] 2018-10-24 01:21:14,220 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:20612 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 20612, None)
[INFO] 2018-10-24 01:21:14,225 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 20612, None)
[INFO] 2018-10-24 01:21:14,226 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 20612, None)
[INFO] 2018-10-24 01:21:14,492 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 01:21:14,492 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 01:21:15,023 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 01:21:15,588 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 01:21:15,602 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 01:21:15,618 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 01:21:15,629 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 01:21:15,630 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 01:21:15,642 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 01:21:15,648 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 01:21:15,661 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 01:21:15,662 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 01:21:15,663 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-592503ef-e4ac-4953-a272-d228fcc02b86
[INFO] 2018-10-24 01:21:15,664 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-662c8528-8d2f-4f28-a2f7-56444c42a01a/pyspark-c11f4d60-337d-427b-8506-2ebb5184d18a
[INFO] 2018-10-24 01:21:15,664 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-662c8528-8d2f-4f28-a2f7-56444c42a01a
[WARN] 2018-10-24 01:25:28,453 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 01:25:29,277 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 01:25:29,304 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_TO_EDW_INVOICE
[INFO] 2018-10-24 01:25:29,561 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 01:25:29,561 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 01:25:29,562 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 01:25:29,562 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 01:25:29,562 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 01:25:29,781 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 33413.
[INFO] 2018-10-24 01:25:29,808 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 01:25:29,829 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 01:25:29,832 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 01:25:29,832 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 01:25:29,842 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-2f5598f2-428a-4fae-a7b8-0c3c6f0d5d83
[INFO] 2018-10-24 01:25:29,860 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 01:25:29,875 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 01:25:30,064 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 01:25:30,120 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 01:25:30,217 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540369530217
[INFO] 2018-10-24 01:25:30,219 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-4a8207a7-6b45-4a45-9340-668edcea367f/userFiles-a4da73f0-1603-4d01-9b66-361529b68f87/etl_config.json
[INFO] 2018-10-24 01:25:30,243 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py with timestamp 1540369530243
[INFO] 2018-10-24 01:25:30,244 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_TO_EDW_INVOICE.py to /tmp/spark-4a8207a7-6b45-4a45-9340-668edcea367f/userFiles-a4da73f0-1603-4d01-9b66-361529b68f87/JB_WORK_TO_EDW_INVOICE.py
[INFO] 2018-10-24 01:25:30,249 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540369530249
[INFO] 2018-10-24 01:25:30,250 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-4a8207a7-6b45-4a45-9340-668edcea367f/userFiles-a4da73f0-1603-4d01-9b66-361529b68f87/packages.zip
[INFO] 2018-10-24 01:25:30,323 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 01:25:30,350 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 16850.
[INFO] 2018-10-24 01:25:30,351 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:16850
[INFO] 2018-10-24 01:25:30,353 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 01:25:30,388 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 16850, None)
[INFO] 2018-10-24 01:25:30,396 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:16850 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 16850, None)
[INFO] 2018-10-24 01:25:30,401 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 16850, None)
[INFO] 2018-10-24 01:25:30,402 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 16850, None)
[INFO] 2018-10-24 01:25:30,711 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 01:25:30,712 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 01:25:31,306 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 01:25:55,407 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 01:25:55,419 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 01:25:55,436 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 01:25:55,447 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 01:25:55,448 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 01:25:55,449 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 01:25:55,456 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 01:25:55,463 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 01:25:55,463 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 01:25:55,464 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4a8207a7-6b45-4a45-9340-668edcea367f/pyspark-7489b19c-8b4c-4181-adce-0d5f2076a07d
[INFO] 2018-10-24 01:25:55,465 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4a8207a7-6b45-4a45-9340-668edcea367f
[INFO] 2018-10-24 01:25:55,465 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-34091352-7876-4dad-b553-241129e899e7
[WARN] 2018-10-24 03:13:33,410 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:13:34,207 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:13:34,233 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_TRUNCATE
[INFO] 2018-10-24 03:13:34,421 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:13:34,421 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:13:34,422 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:13:34,422 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:13:34,432 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:13:34,668 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 34235.
[INFO] 2018-10-24 03:13:34,698 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:13:34,721 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:13:34,725 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:13:34,725 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:13:34,736 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-01b9cf7a-f602-4c3c-8dbc-13054e180be0
[INFO] 2018-10-24 03:13:34,757 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:13:34,774 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:13:34,965 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:13:35,017 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:13:35,112 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376015112
[INFO] 2018-10-24 03:13:35,114 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-67fb2d19-78f2-4677-b84e-c3359a0cf04c/userFiles-e500e7a7-31f6-4a9a-92f7-e9dce87c377e/etl_config.json
[INFO] 2018-10-24 03:13:35,129 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py with timestamp 1540376015129
[INFO] 2018-10-24 03:13:35,130 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py to /tmp/spark-67fb2d19-78f2-4677-b84e-c3359a0cf04c/userFiles-e500e7a7-31f6-4a9a-92f7-e9dce87c377e/JB_WORK_INVOICE_TRUNCATE.py
[INFO] 2018-10-24 03:13:35,134 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376015134
[INFO] 2018-10-24 03:13:35,134 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-67fb2d19-78f2-4677-b84e-c3359a0cf04c/userFiles-e500e7a7-31f6-4a9a-92f7-e9dce87c377e/packages.zip
[INFO] 2018-10-24 03:13:35,203 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:13:35,226 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 28453.
[INFO] 2018-10-24 03:13:35,227 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:28453
[INFO] 2018-10-24 03:13:35,229 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:13:35,263 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 28453, None)
[INFO] 2018-10-24 03:13:35,269 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:28453 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 28453, None)
[INFO] 2018-10-24 03:13:35,275 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 28453, None)
[INFO] 2018-10-24 03:13:35,275 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 28453, None)
[INFO] 2018-10-24 03:13:35,586 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:13:35,586 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:13:36,152 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:13:36,949 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:13:36,962 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:13:36,975 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:13:36,989 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:13:36,989 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:13:37,000 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:13:37,006 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:13:37,022 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:13:37,023 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:13:37,025 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-67fb2d19-78f2-4677-b84e-c3359a0cf04c/pyspark-2c74bd2a-e0f9-4d3d-82c0-941db71ff380
[INFO] 2018-10-24 03:13:37,026 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-67fb2d19-78f2-4677-b84e-c3359a0cf04c
[INFO] 2018-10-24 03:13:37,027 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f5314bba-156a-48f2-bbd4-8bb8a569b3f0
[WARN] 2018-10-24 03:14:09,757 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:14:10,561 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:14:10,589 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE
[INFO] 2018-10-24 03:14:10,809 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:14:10,810 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:14:10,810 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:14:10,811 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:14:10,811 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:14:11,054 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 36922.
[INFO] 2018-10-24 03:14:11,084 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:14:11,108 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:14:11,112 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:14:11,112 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:14:11,123 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-58ca081c-3811-4281-8049-d91af8a84191
[INFO] 2018-10-24 03:14:11,145 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:14:11,161 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:14:11,371 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:14:11,432 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:14:11,543 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376051542
[INFO] 2018-10-24 03:14:11,546 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-c1e6f528-9b75-40c6-ae84-91c3a8ab9a0c/userFiles-84d654e9-2ff9-4d67-923a-a6c7f874f9ee/etl_config.json
[INFO] 2018-10-24 03:14:11,560 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py with timestamp 1540376051560
[INFO] 2018-10-24 03:14:11,561 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py to /tmp/spark-c1e6f528-9b75-40c6-ae84-91c3a8ab9a0c/userFiles-84d654e9-2ff9-4d67-923a-a6c7f874f9ee/JB_WORK_INVOICE.py
[INFO] 2018-10-24 03:14:11,565 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376051565
[INFO] 2018-10-24 03:14:11,565 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-c1e6f528-9b75-40c6-ae84-91c3a8ab9a0c/userFiles-84d654e9-2ff9-4d67-923a-a6c7f874f9ee/packages.zip
[INFO] 2018-10-24 03:14:11,635 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:14:11,662 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 16678.
[INFO] 2018-10-24 03:14:11,663 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:16678
[INFO] 2018-10-24 03:14:11,665 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:14:11,699 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 16678, None)
[INFO] 2018-10-24 03:14:11,706 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:16678 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 16678, None)
[INFO] 2018-10-24 03:14:11,709 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 16678, None)
[INFO] 2018-10-24 03:14:11,710 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 16678, None)
[INFO] 2018-10-24 03:14:12,022 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:14:12,023 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:14:12,560 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:14:24,802 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:14:24,815 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:14:24,828 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:14:24,838 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:14:24,838 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:14:24,850 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:14:24,856 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:14:24,867 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:14:24,868 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:14:24,869 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c1e6f528-9b75-40c6-ae84-91c3a8ab9a0c
[INFO] 2018-10-24 03:14:24,870 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c50c3478-5632-4668-a0c4-91771ad30a61
[INFO] 2018-10-24 03:14:24,870 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c1e6f528-9b75-40c6-ae84-91c3a8ab9a0c/pyspark-29c13e8e-20f9-4f1f-bfd7-e94e053f2b5d
[WARN] 2018-10-24 03:15:50,887 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:15:51,715 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:15:51,742 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE
[INFO] 2018-10-24 03:15:51,922 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:15:51,922 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:15:51,923 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:15:51,923 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:15:51,937 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:15:52,141 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 36704.
[INFO] 2018-10-24 03:15:52,167 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:15:52,187 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:15:52,190 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:15:52,191 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:15:52,200 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-9c0aa82e-c330-4453-a0fa-6d649c6fce32
[INFO] 2018-10-24 03:15:52,218 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:15:52,233 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:15:52,433 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:15:52,508 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:15:52,611 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376152611
[INFO] 2018-10-24 03:15:52,613 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-3884ad13-6820-40b8-83eb-62124a9e913d/userFiles-b7230704-f866-4980-a68e-cc4d205c0223/etl_config.json
[INFO] 2018-10-24 03:15:52,629 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py with timestamp 1540376152629
[INFO] 2018-10-24 03:15:52,630 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py to /tmp/spark-3884ad13-6820-40b8-83eb-62124a9e913d/userFiles-b7230704-f866-4980-a68e-cc4d205c0223/JB_WORK_INVOICE.py
[INFO] 2018-10-24 03:15:52,634 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376152634
[INFO] 2018-10-24 03:15:52,635 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-3884ad13-6820-40b8-83eb-62124a9e913d/userFiles-b7230704-f866-4980-a68e-cc4d205c0223/packages.zip
[INFO] 2018-10-24 03:15:52,707 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:15:52,735 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 16614.
[INFO] 2018-10-24 03:15:52,736 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:16614
[INFO] 2018-10-24 03:15:52,738 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:15:52,772 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 16614, None)
[INFO] 2018-10-24 03:15:52,780 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:16614 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 16614, None)
[INFO] 2018-10-24 03:15:52,787 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 16614, None)
[INFO] 2018-10-24 03:15:52,787 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 16614, None)
[INFO] 2018-10-24 03:15:53,077 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:15:53,077 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:15:53,616 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:15:54,733 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:15:54,746 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:15:54,762 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:15:54,774 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:15:54,774 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:15:54,787 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:15:54,794 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:15:54,803 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:15:54,804 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:15:54,805 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-3884ad13-6820-40b8-83eb-62124a9e913d/pyspark-9f769ad5-eefa-4248-809b-50755e0b7da4
[INFO] 2018-10-24 03:15:54,805 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-3884ad13-6820-40b8-83eb-62124a9e913d
[INFO] 2018-10-24 03:15:54,806 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-05449299-7002-474a-91bc-8c04ff2b5844
[WARN] 2018-10-24 03:16:00,623 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:16:01,479 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:16:01,509 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_TRUNCATE
[INFO] 2018-10-24 03:16:01,787 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:16:01,788 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:16:01,788 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:16:01,789 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:16:01,789 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:16:02,008 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 30852.
[INFO] 2018-10-24 03:16:02,035 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:16:02,055 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:16:02,059 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:16:02,059 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:16:02,069 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-f964d8f9-2501-44a4-9d49-dc783e4cfd69
[INFO] 2018-10-24 03:16:02,088 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:16:02,102 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:16:02,285 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:16:02,336 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:16:02,431 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376162431
[INFO] 2018-10-24 03:16:02,433 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-1228602c-43b0-45e6-b361-549740536430/userFiles-5fa3d7cc-4bd9-4f5e-a23a-a7126447d413/etl_config.json
[INFO] 2018-10-24 03:16:02,448 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py with timestamp 1540376162448
[INFO] 2018-10-24 03:16:02,448 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py to /tmp/spark-1228602c-43b0-45e6-b361-549740536430/userFiles-5fa3d7cc-4bd9-4f5e-a23a-a7126447d413/JB_WORK_INVOICE_TRUNCATE.py
[INFO] 2018-10-24 03:16:02,451 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376162451
[INFO] 2018-10-24 03:16:02,452 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-1228602c-43b0-45e6-b361-549740536430/userFiles-5fa3d7cc-4bd9-4f5e-a23a-a7126447d413/packages.zip
[INFO] 2018-10-24 03:16:02,523 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:16:02,550 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 15707.
[INFO] 2018-10-24 03:16:02,551 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:15707
[INFO] 2018-10-24 03:16:02,553 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:16:02,587 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 15707, None)
[INFO] 2018-10-24 03:16:02,595 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:15707 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 15707, None)
[INFO] 2018-10-24 03:16:02,600 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 15707, None)
[INFO] 2018-10-24 03:16:02,601 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 15707, None)
[INFO] 2018-10-24 03:16:02,894 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:16:02,895 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:16:03,463 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:16:05,502 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:16:05,515 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:16:05,526 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:16:05,542 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:16:05,543 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:16:05,552 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:16:05,558 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:16:05,567 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:16:05,567 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:16:05,569 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-1228602c-43b0-45e6-b361-549740536430
[INFO] 2018-10-24 03:16:05,569 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-1228602c-43b0-45e6-b361-549740536430/pyspark-0a146fca-6b7b-4af3-8103-d0ec6cec86b4
[INFO] 2018-10-24 03:16:05,570 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-42596bae-f7cb-471d-983d-106db0cfcaf1
[WARN] 2018-10-24 03:16:10,319 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:16:11,134 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:16:11,162 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE
[INFO] 2018-10-24 03:16:11,335 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:16:11,336 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:16:11,336 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:16:11,336 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:16:11,337 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:16:11,556 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 21770.
[INFO] 2018-10-24 03:16:11,586 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:16:11,607 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:16:11,611 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:16:11,611 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:16:11,621 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-f0874b34-3555-4157-b4cd-59039d46bc16
[INFO] 2018-10-24 03:16:11,640 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:16:11,655 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:16:11,841 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:16:11,895 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:16:11,994 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376171994
[INFO] 2018-10-24 03:16:11,996 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-d3a77558-51a8-4c4d-b3f0-6e5dbeca0880/userFiles-f9bf918c-f90f-4e7e-bfc3-7b5bfea0b9b9/etl_config.json
[INFO] 2018-10-24 03:16:12,011 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py with timestamp 1540376172011
[INFO] 2018-10-24 03:16:12,012 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py to /tmp/spark-d3a77558-51a8-4c4d-b3f0-6e5dbeca0880/userFiles-f9bf918c-f90f-4e7e-bfc3-7b5bfea0b9b9/JB_WORK_INVOICE.py
[INFO] 2018-10-24 03:16:12,017 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376172017
[INFO] 2018-10-24 03:16:12,018 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-d3a77558-51a8-4c4d-b3f0-6e5dbeca0880/userFiles-f9bf918c-f90f-4e7e-bfc3-7b5bfea0b9b9/packages.zip
[INFO] 2018-10-24 03:16:12,086 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:16:12,111 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 21323.
[INFO] 2018-10-24 03:16:12,112 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:21323
[INFO] 2018-10-24 03:16:12,114 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:16:12,147 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 21323, None)
[INFO] 2018-10-24 03:16:12,153 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:21323 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 21323, None)
[INFO] 2018-10-24 03:16:12,156 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 21323, None)
[INFO] 2018-10-24 03:16:12,156 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 21323, None)
[INFO] 2018-10-24 03:16:12,451 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:16:12,451 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:16:13,038 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:16:14,161 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:16:14,175 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:16:14,192 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:16:14,201 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:16:14,202 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:16:14,212 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:16:14,218 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:16:14,227 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:16:14,229 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:16:14,230 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d3a77558-51a8-4c4d-b3f0-6e5dbeca0880
[INFO] 2018-10-24 03:16:14,231 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d3a77558-51a8-4c4d-b3f0-6e5dbeca0880/pyspark-92fca0db-e71b-4090-aebc-5b3fe2f9d5e8
[INFO] 2018-10-24 03:16:14,231 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-22ca1ae5-67aa-4e23-8261-cd8281398a8b
[WARN] 2018-10-24 03:25:32,720 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:25:33,481 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:25:33,483 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-7a1927b7-0d76-4f73-b189-3185471992d7
[WARN] 2018-10-24 03:25:49,227 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:25:50,151 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:25:50,178 org.apache.spark.SparkContext logInfo - Submitted application: JB_BOOKING_DAY_FLAG_TEMP_TRUNCATE
[INFO] 2018-10-24 03:25:50,422 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:25:50,423 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:25:50,423 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:25:50,424 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:25:50,432 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:25:50,664 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 22908.
[INFO] 2018-10-24 03:25:50,695 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:25:50,718 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:25:50,722 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:25:50,723 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:25:50,734 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-3d604902-7a44-49dc-b4ac-443c9b8abf0c
[INFO] 2018-10-24 03:25:50,756 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:25:50,773 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:25:50,974 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:25:51,034 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:25:51,142 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376751141
[INFO] 2018-10-24 03:25:51,144 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-8896ea8e-fe4d-4160-bb60-abcf64f77cc7/userFiles-9429df15-703f-49ea-8455-edf0fc239fda/etl_config.json
[INFO] 2018-10-24 03:25:51,159 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_BOOKING_DAY_FLAG_TEMP_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_BOOKING_DAY_FLAG_TEMP_TRUNCATE.py with timestamp 1540376751159
[INFO] 2018-10-24 03:25:51,160 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_BOOKING_DAY_FLAG_TEMP_TRUNCATE.py to /tmp/spark-8896ea8e-fe4d-4160-bb60-abcf64f77cc7/userFiles-9429df15-703f-49ea-8455-edf0fc239fda/JB_BOOKING_DAY_FLAG_TEMP_TRUNCATE.py
[INFO] 2018-10-24 03:25:51,164 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376751164
[INFO] 2018-10-24 03:25:51,165 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-8896ea8e-fe4d-4160-bb60-abcf64f77cc7/userFiles-9429df15-703f-49ea-8455-edf0fc239fda/packages.zip
[INFO] 2018-10-24 03:25:51,251 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:25:51,278 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 26420.
[INFO] 2018-10-24 03:25:51,279 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:26420
[INFO] 2018-10-24 03:25:51,281 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:25:51,317 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 26420, None)
[INFO] 2018-10-24 03:25:51,323 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:26420 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 26420, None)
[INFO] 2018-10-24 03:25:51,327 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 26420, None)
[INFO] 2018-10-24 03:25:51,328 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 26420, None)
[INFO] 2018-10-24 03:25:51,614 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:25:51,615 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:25:52,253 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:25:52,928 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:25:52,942 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:25:52,956 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:25:52,965 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:25:52,966 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:25:52,978 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:25:52,986 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:25:52,995 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:25:52,996 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:25:52,998 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-8896ea8e-fe4d-4160-bb60-abcf64f77cc7
[INFO] 2018-10-24 03:25:52,999 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-69e2fe98-908d-409e-ac28-84ca23479dd5
[INFO] 2018-10-24 03:25:53,000 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-8896ea8e-fe4d-4160-bb60-abcf64f77cc7/pyspark-8987d1f0-0e96-4f1f-af54-732ef6f7f8f6
[WARN] 2018-10-24 03:26:58,160 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:26:58,965 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:26:58,993 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP_TRUNCATE
[INFO] 2018-10-24 03:26:59,135 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:26:59,136 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:26:59,136 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:26:59,136 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:26:59,137 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:26:59,355 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 31879.
[INFO] 2018-10-24 03:26:59,384 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:26:59,406 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:26:59,409 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:26:59,410 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:26:59,420 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-07e63ff9-2798-4aad-9496-b43535de92c7
[INFO] 2018-10-24 03:26:59,439 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:26:59,455 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:26:59,656 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:26:59,711 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:26:59,809 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376819808
[INFO] 2018-10-24 03:26:59,811 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-f5c1de61-8a03-4fa8-9b20-d692a48ad334/userFiles-5a6d5a71-c7ec-4620-afa4-bb08c2b891f1/etl_config.json
[INFO] 2018-10-24 03:26:59,827 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py with timestamp 1540376819827
[INFO] 2018-10-24 03:26:59,827 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py to /tmp/spark-f5c1de61-8a03-4fa8-9b20-d692a48ad334/userFiles-5a6d5a71-c7ec-4620-afa4-bb08c2b891f1/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py
[INFO] 2018-10-24 03:26:59,832 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376819832
[INFO] 2018-10-24 03:26:59,833 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-f5c1de61-8a03-4fa8-9b20-d692a48ad334/userFiles-5a6d5a71-c7ec-4620-afa4-bb08c2b891f1/packages.zip
[INFO] 2018-10-24 03:26:59,904 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:26:59,929 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 26672.
[INFO] 2018-10-24 03:26:59,930 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:26672
[INFO] 2018-10-24 03:26:59,932 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:26:59,965 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 26672, None)
[INFO] 2018-10-24 03:26:59,971 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:26672 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 26672, None)
[INFO] 2018-10-24 03:26:59,974 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 26672, None)
[INFO] 2018-10-24 03:26:59,975 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 26672, None)
[INFO] 2018-10-24 03:27:00,264 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:27:00,265 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:27:00,785 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:27:01,788 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:27:01,799 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:27:01,813 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:27:01,823 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:27:01,824 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:27:01,832 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:27:01,838 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:27:01,847 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:27:01,848 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:27:01,850 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f5c1de61-8a03-4fa8-9b20-d692a48ad334
[INFO] 2018-10-24 03:27:01,851 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-3e27d7c1-e184-48c1-b0be-e30c60fe9661
[INFO] 2018-10-24 03:27:01,851 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f5c1de61-8a03-4fa8-9b20-d692a48ad334/pyspark-a3771198-0aae-48eb-a8ce-8c72399bc00f
[WARN] 2018-10-24 03:27:08,270 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:27:09,128 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:27:09,155 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP
[INFO] 2018-10-24 03:27:09,476 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:27:09,476 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:27:09,477 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:27:09,477 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:27:09,485 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:27:09,688 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 33024.
[INFO] 2018-10-24 03:27:09,714 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:27:09,735 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:27:09,738 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:27:09,738 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:27:09,747 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-fde70648-0536-41ae-95f6-567a4695aa7b
[INFO] 2018-10-24 03:27:09,765 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:27:09,780 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:27:09,964 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:27:10,015 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:27:10,110 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376830109
[INFO] 2018-10-24 03:27:10,112 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/userFiles-7c6c9151-fda0-4e36-af08-550afe3a7a2d/etl_config.json
[INFO] 2018-10-24 03:27:10,126 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py with timestamp 1540376830126
[INFO] 2018-10-24 03:27:10,127 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py to /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/userFiles-7c6c9151-fda0-4e36-af08-550afe3a7a2d/JB_WORK_INVOICE_DATAPREP.py
[INFO] 2018-10-24 03:27:10,131 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540376830131
[INFO] 2018-10-24 03:27:10,132 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/userFiles-7c6c9151-fda0-4e36-af08-550afe3a7a2d/packages.zip
[INFO] 2018-10-24 03:27:10,198 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:27:10,225 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31360.
[INFO] 2018-10-24 03:27:10,226 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:31360
[INFO] 2018-10-24 03:27:10,228 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:27:10,266 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 31360, None)
[INFO] 2018-10-24 03:27:10,273 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:31360 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 31360, None)
[INFO] 2018-10-24 03:27:10,279 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 31360, None)
[INFO] 2018-10-24 03:27:10,280 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 31360, None)
[INFO] 2018-10-24 03:27:10,563 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:27:10,563 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:27:11,148 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:27:14,415 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 223.128079 ms
[INFO] 2018-10-24 03:27:14,576 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307
[INFO] 2018-10-24 03:27:14,604 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307) with 1 output partitions
[INFO] 2018-10-24 03:27:14,605 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307)
[INFO] 2018-10-24 03:27:14,605 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 03:27:14,607 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 03:27:14,622 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307), which has no missing parents
[INFO] 2018-10-24 03:27:14,698 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 03:27:14,731 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 03:27:14,736 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:31360 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 03:27:14,739 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 03:27:14,758 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 03:27:14,761 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 03:27:14,814 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 03:27:14,829 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 03:27:14,835 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540376830109
[INFO] 2018-10-24 03:27:14,868 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/userFiles-7c6c9151-fda0-4e36-af08-550afe3a7a2d/etl_config.json
[INFO] 2018-10-24 03:27:14,874 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py with timestamp 1540376830126
[INFO] 2018-10-24 03:27:14,876 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py has been previously copied to /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/userFiles-7c6c9151-fda0-4e36-af08-550afe3a7a2d/JB_WORK_INVOICE_DATAPREP.py
[INFO] 2018-10-24 03:27:14,881 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540376830131
[INFO] 2018-10-24 03:27:14,882 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/userFiles-7c6c9151-fda0-4e36-af08-550afe3a7a2d/packages.zip
[INFO] 2018-10-24 03:27:15,827 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 03:27:15,871 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 534, boot = 437, init = 96, finish = 1
[INFO] 2018-10-24 03:27:15,894 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1661 bytes result sent to driver
[INFO] 2018-10-24 03:27:15,907 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 1107 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 03:27:15,912 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 03:27:15,924 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307) finished in 1.279 s
[INFO] 2018-10-24 03:27:15,931 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:307, took 1.353633 s
[INFO] 2018-10-24 03:27:16,007 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308
[INFO] 2018-10-24 03:27:16,008 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308) with 1 output partitions
[INFO] 2018-10-24 03:27:16,009 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308)
[INFO] 2018-10-24 03:27:16,009 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 03:27:16,010 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 03:27:16,011 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308), which has no missing parents
[INFO] 2018-10-24 03:27:16,016 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 03:27:16,020 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 03:27:16,021 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:31360 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 03:27:16,023 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 03:27:16,024 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 03:27:16,024 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 03:27:16,026 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 03:27:16,027 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 03:27:16,412 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 03:27:16,416 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 51, boot = -488, init = 538, finish = 1
[INFO] 2018-10-24 03:27:16,420 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
[INFO] 2018-10-24 03:27:16,424 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 399 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 03:27:16,424 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 03:27:16,426 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308) finished in 0.413 s
[INFO] 2018-10-24 03:27:16,428 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:308, took 0.420694 s
[INFO] 2018-10-24 03:35:47,196 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:35:47,209 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:35:47,230 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:35:47,252 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:35:47,253 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:35:47,253 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:35:47,258 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:35:47,270 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:35:47,271 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:35:47,273 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49
[INFO] 2018-10-24 03:35:47,274 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-eccda4ce-237b-4b5f-9dfe-e8d131368f49/pyspark-4f60e2fd-0623-4f16-a4a2-419cfa6bc2e2
[INFO] 2018-10-24 03:35:47,275 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f055e75b-837f-4259-af4e-5928914329fd
[WARN] 2018-10-24 03:39:17,041 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:39:17,914 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:39:17,942 org.apache.spark.SparkContext logInfo - Submitted application: JB_STG_INVOICE_TRUNCATE
[INFO] 2018-10-24 03:39:18,148 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:39:18,149 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:39:18,149 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:39:18,149 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:39:18,150 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:39:18,380 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 14581.
[INFO] 2018-10-24 03:39:18,408 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:39:18,428 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:39:18,431 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:39:18,432 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:39:18,441 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-80fbae25-a08c-462e-82ff-1fb4cf674c89
[INFO] 2018-10-24 03:39:18,458 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:39:18,472 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:39:18,651 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:39:18,716 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:39:18,811 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540377558811
[INFO] 2018-10-24 03:39:18,814 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-b8d627ba-099b-432b-8f55-cd88e61a3848/userFiles-be8b0395-8bcd-4af5-a78f-84de41f782d3/etl_config.json
[INFO] 2018-10-24 03:39:18,829 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_STG_INVOICE_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_STG_INVOICE_TRUNCATE.py with timestamp 1540377558829
[INFO] 2018-10-24 03:39:18,829 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_STG_INVOICE_TRUNCATE.py to /tmp/spark-b8d627ba-099b-432b-8f55-cd88e61a3848/userFiles-be8b0395-8bcd-4af5-a78f-84de41f782d3/JB_STG_INVOICE_TRUNCATE.py
[INFO] 2018-10-24 03:39:18,834 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540377558834
[INFO] 2018-10-24 03:39:18,835 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-b8d627ba-099b-432b-8f55-cd88e61a3848/userFiles-be8b0395-8bcd-4af5-a78f-84de41f782d3/packages.zip
[INFO] 2018-10-24 03:39:18,910 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:39:18,936 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 28635.
[INFO] 2018-10-24 03:39:18,937 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:28635
[INFO] 2018-10-24 03:39:18,939 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:39:18,974 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 28635, None)
[INFO] 2018-10-24 03:39:18,979 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:28635 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 28635, None)
[INFO] 2018-10-24 03:39:18,988 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 28635, None)
[INFO] 2018-10-24 03:39:18,990 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 28635, None)
[INFO] 2018-10-24 03:39:19,300 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:39:19,301 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:39:19,867 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:39:20,401 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:39:20,417 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:39:20,436 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:39:20,446 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:39:20,446 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:39:20,458 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:39:20,463 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:39:20,471 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:39:20,472 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:39:20,473 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-b8d627ba-099b-432b-8f55-cd88e61a3848/pyspark-9f037c57-8a14-4d26-a810-931cee8d4d8a
[INFO] 2018-10-24 03:39:20,474 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-b8d627ba-099b-432b-8f55-cd88e61a3848
[INFO] 2018-10-24 03:39:20,474 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4bcdd695-98b8-48d2-91d3-d5a05805b1b9
[WARN] 2018-10-24 03:39:28,838 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:39:29,655 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:39:29,682 org.apache.spark.SparkContext logInfo - Submitted application: JB_STG_INVOICE
[INFO] 2018-10-24 03:39:29,873 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:39:29,873 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:39:29,874 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:39:29,874 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:39:29,882 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:39:30,087 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 28585.
[INFO] 2018-10-24 03:39:30,115 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:39:30,137 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:39:30,140 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:39:30,141 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:39:30,150 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-e604ffd5-7407-4728-973c-6968aba475c5
[INFO] 2018-10-24 03:39:30,169 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:39:30,184 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:39:30,379 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:39:30,440 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:39:30,548 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540377570547
[INFO] 2018-10-24 03:39:30,550 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-bb58780c-9bcc-4ae2-9254-a22b66fd92d5/userFiles-d37d96af-5a98-423d-9f0a-f15bd2f77f0a/etl_config.json
[INFO] 2018-10-24 03:39:30,564 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_STG_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_STG_INVOICE.py with timestamp 1540377570564
[INFO] 2018-10-24 03:39:30,565 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_STG_INVOICE.py to /tmp/spark-bb58780c-9bcc-4ae2-9254-a22b66fd92d5/userFiles-d37d96af-5a98-423d-9f0a-f15bd2f77f0a/JB_STG_INVOICE.py
[INFO] 2018-10-24 03:39:30,569 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540377570569
[INFO] 2018-10-24 03:39:30,570 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-bb58780c-9bcc-4ae2-9254-a22b66fd92d5/userFiles-d37d96af-5a98-423d-9f0a-f15bd2f77f0a/packages.zip
[INFO] 2018-10-24 03:39:30,642 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:39:30,670 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 16156.
[INFO] 2018-10-24 03:39:30,672 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:16156
[INFO] 2018-10-24 03:39:30,674 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:39:30,707 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 16156, None)
[INFO] 2018-10-24 03:39:30,713 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:16156 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 16156, None)
[INFO] 2018-10-24 03:39:30,716 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 16156, None)
[INFO] 2018-10-24 03:39:30,717 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 16156, None)
[INFO] 2018-10-24 03:39:31,004 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:39:31,005 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:39:31,537 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:39:56,681 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:39:56,693 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:39:56,710 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:39:56,723 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:39:56,724 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:39:56,725 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:39:56,730 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:39:56,741 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:39:56,741 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:39:56,742 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-8a4667fd-d8ce-4ecb-b892-4fa4191d05c2
[INFO] 2018-10-24 03:39:56,743 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-bb58780c-9bcc-4ae2-9254-a22b66fd92d5
[INFO] 2018-10-24 03:39:56,744 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-bb58780c-9bcc-4ae2-9254-a22b66fd92d5/pyspark-e0f13138-3e38-4a16-97cc-7ccb8463252b
[WARN] 2018-10-24 03:40:09,237 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:40:10,097 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:40:10,124 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_TRUNCATE
[INFO] 2018-10-24 03:40:10,341 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:40:10,342 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:40:10,342 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:40:10,342 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:40:10,343 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:40:10,575 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 34961.
[INFO] 2018-10-24 03:40:10,604 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:40:10,625 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:40:10,629 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:40:10,629 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:40:10,639 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-2ac9d6cb-56ef-43d7-982b-d3cbf9b7a330
[INFO] 2018-10-24 03:40:10,657 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:40:10,672 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:40:10,886 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:40:10,944 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:40:11,054 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540377611054
[INFO] 2018-10-24 03:40:11,057 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-ffdde8fe-c65c-4204-9f66-baa24d5c14ff/userFiles-c260c395-ae6f-40ea-b74d-a0508b98334c/etl_config.json
[INFO] 2018-10-24 03:40:11,073 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py with timestamp 1540377611073
[INFO] 2018-10-24 03:40:11,073 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py to /tmp/spark-ffdde8fe-c65c-4204-9f66-baa24d5c14ff/userFiles-c260c395-ae6f-40ea-b74d-a0508b98334c/JB_WORK_INVOICE_TRUNCATE.py
[INFO] 2018-10-24 03:40:11,079 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540377611079
[INFO] 2018-10-24 03:40:11,079 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-ffdde8fe-c65c-4204-9f66-baa24d5c14ff/userFiles-c260c395-ae6f-40ea-b74d-a0508b98334c/packages.zip
[INFO] 2018-10-24 03:40:11,159 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:40:11,185 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32472.
[INFO] 2018-10-24 03:40:11,187 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:32472
[INFO] 2018-10-24 03:40:11,189 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:40:11,226 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 32472, None)
[INFO] 2018-10-24 03:40:11,232 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:32472 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 32472, None)
[INFO] 2018-10-24 03:40:11,236 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 32472, None)
[INFO] 2018-10-24 03:40:11,237 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 32472, None)
[INFO] 2018-10-24 03:40:11,558 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:40:11,558 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:40:12,159 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:40:12,643 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:40:12,657 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:40:12,670 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:40:12,679 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:40:12,679 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:40:12,692 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:40:12,699 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:40:12,707 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:40:12,708 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:40:12,709 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-ffdde8fe-c65c-4204-9f66-baa24d5c14ff/pyspark-e10570e9-abbe-475d-9d5e-50eb37702614
[INFO] 2018-10-24 03:40:12,710 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-ffdde8fe-c65c-4204-9f66-baa24d5c14ff
[INFO] 2018-10-24 03:40:12,710 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-a0a0dce3-240f-47a8-9026-d843fdf6f19b
[WARN] 2018-10-24 03:40:20,019 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 03:40:20,865 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 03:40:20,892 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE
[INFO] 2018-10-24 03:40:21,061 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 03:40:21,062 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 03:40:21,062 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 03:40:21,062 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 03:40:21,075 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 03:40:21,276 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 9935.
[INFO] 2018-10-24 03:40:21,304 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 03:40:21,324 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 03:40:21,327 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 03:40:21,328 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 03:40:21,337 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-ebedcad0-324e-45a9-8000-aee7ecf031f4
[INFO] 2018-10-24 03:40:21,355 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 03:40:21,369 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 03:40:21,570 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 03:40:21,630 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:40:21,746 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540377621745
[INFO] 2018-10-24 03:40:21,748 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-57a4fc0e-5dde-4666-b41e-4ff542b8200a/userFiles-7610789d-d58f-486a-834f-85d627dfa70c/etl_config.json
[INFO] 2018-10-24 03:40:21,762 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py with timestamp 1540377621762
[INFO] 2018-10-24 03:40:21,762 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py to /tmp/spark-57a4fc0e-5dde-4666-b41e-4ff542b8200a/userFiles-7610789d-d58f-486a-834f-85d627dfa70c/JB_WORK_INVOICE.py
[INFO] 2018-10-24 03:40:21,766 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540377621766
[INFO] 2018-10-24 03:40:21,766 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-57a4fc0e-5dde-4666-b41e-4ff542b8200a/userFiles-7610789d-d58f-486a-834f-85d627dfa70c/packages.zip
[INFO] 2018-10-24 03:40:21,845 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 03:40:21,872 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 20429.
[INFO] 2018-10-24 03:40:21,873 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:20429
[INFO] 2018-10-24 03:40:21,875 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 03:40:21,908 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 20429, None)
[INFO] 2018-10-24 03:40:21,915 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:20429 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 20429, None)
[INFO] 2018-10-24 03:40:21,919 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 20429, None)
[INFO] 2018-10-24 03:40:21,920 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 20429, None)
[INFO] 2018-10-24 03:40:22,217 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 03:40:22,218 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 03:40:22,806 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 03:40:32,546 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 03:40:32,558 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 03:40:32,571 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 03:40:32,580 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 03:40:32,580 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 03:40:32,592 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 03:40:32,598 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 03:40:32,609 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 03:40:32,610 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 03:40:32,612 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4cf02941-6be4-4379-adef-e486836c6b3b
[INFO] 2018-10-24 03:40:32,613 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-57a4fc0e-5dde-4666-b41e-4ff542b8200a
[INFO] 2018-10-24 03:40:32,613 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-57a4fc0e-5dde-4666-b41e-4ff542b8200a/pyspark-4a57f9dd-0424-404d-a5cd-c28732734a70
[WARN] 2018-10-24 04:17:37,966 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:17:38,354 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:17:38,357 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-be6b31e8-0a52-4b10-9c9f-3f6fcf621143
[WARN] 2018-10-24 04:18:24,653 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:18:25,121 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:18:25,123 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-50e0c879-0c6c-4cf5-8129-8b425543f9d8
[WARN] 2018-10-24 04:19:34,379 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:19:34,816 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:19:34,818 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-07236b94-cdc0-4736-88ff-b7402fb72d3c
[WARN] 2018-10-24 04:20:14,132 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:20:14,529 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:20:14,531 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-6eced9e8-0235-46bd-8065-8dd370d5ee50
[WARN] 2018-10-24 04:21:09,528 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:21:10,332 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:21:10,359 org.apache.spark.SparkContext logInfo - Submitted application: JB_STG_BOOKING_INCR
[INFO] 2018-10-24 04:21:10,543 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:21:10,543 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:21:10,544 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:21:10,544 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:21:10,545 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:21:10,746 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 23375.
[INFO] 2018-10-24 04:21:10,772 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:21:10,792 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:21:10,796 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:21:10,796 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:21:10,807 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-2478c177-c81f-4124-9ef5-e6425a96bcbd
[INFO] 2018-10-24 04:21:10,825 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:21:10,841 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 04:21:11,023 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 04:21:11,088 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:21:11,199 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380071199
[INFO] 2018-10-24 04:21:11,202 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-5e4bd47c-3615-4e7a-87f1-d3b84839f785/userFiles-82b3298e-b74a-40c8-a29a-4862974adba7/etl_config.json
[INFO] 2018-10-24 04:21:11,218 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_STG_BOOKING_INCR.py at file:/home/spark/EBI_Project/jobs/SCH/JB_STG_BOOKING_INCR.py with timestamp 1540380071218
[INFO] 2018-10-24 04:21:11,219 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_STG_BOOKING_INCR.py to /tmp/spark-5e4bd47c-3615-4e7a-87f1-d3b84839f785/userFiles-82b3298e-b74a-40c8-a29a-4862974adba7/JB_STG_BOOKING_INCR.py
[INFO] 2018-10-24 04:21:11,223 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380071223
[INFO] 2018-10-24 04:21:11,223 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-5e4bd47c-3615-4e7a-87f1-d3b84839f785/userFiles-82b3298e-b74a-40c8-a29a-4862974adba7/packages.zip
[INFO] 2018-10-24 04:21:11,288 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:21:11,314 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 28916.
[INFO] 2018-10-24 04:21:11,314 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:28916
[INFO] 2018-10-24 04:21:11,316 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:21:11,350 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 28916, None)
[INFO] 2018-10-24 04:21:11,356 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:28916 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 28916, None)
[INFO] 2018-10-24 04:21:11,361 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 28916, None)
[INFO] 2018-10-24 04:21:11,362 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 28916, None)
[INFO] 2018-10-24 04:21:11,650 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:21:11,651 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:21:12,169 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:21:12,542 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:21:12,557 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:21:12,570 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:21:12,579 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:21:12,579 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:21:12,586 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:21:12,590 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:21:12,610 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:21:12,611 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:21:12,613 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-5e4bd47c-3615-4e7a-87f1-d3b84839f785/pyspark-7c50db89-47ee-40cf-adfc-cb02f04fb310
[INFO] 2018-10-24 04:21:12,613 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-5e4bd47c-3615-4e7a-87f1-d3b84839f785
[INFO] 2018-10-24 04:21:12,614 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c2e92b2d-3a8a-49a7-a66b-4f97f9b62a70
[WARN] 2018-10-24 04:21:37,764 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:21:38,541 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:21:38,568 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_TRUNCATE
[INFO] 2018-10-24 04:21:38,782 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:21:38,782 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:21:38,783 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:21:38,783 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:21:38,783 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:21:39,017 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 29066.
[INFO] 2018-10-24 04:21:39,050 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:21:39,074 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:21:39,078 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:21:39,079 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:21:39,089 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-566c455e-f3f3-4315-bbbb-3a2ce39e57d4
[INFO] 2018-10-24 04:21:39,110 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:21:39,127 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 04:21:39,342 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 04:21:39,400 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:21:39,508 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380099508
[INFO] 2018-10-24 04:21:39,511 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-e17955b9-4e0b-419b-b353-08b986a10b5b/userFiles-48943beb-dc07-46f5-9beb-b0a2d42f2d1b/etl_config.json
[INFO] 2018-10-24 04:21:39,525 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py with timestamp 1540380099525
[INFO] 2018-10-24 04:21:39,526 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_TRUNCATE.py to /tmp/spark-e17955b9-4e0b-419b-b353-08b986a10b5b/userFiles-48943beb-dc07-46f5-9beb-b0a2d42f2d1b/JB_WORK_INVOICE_TRUNCATE.py
[INFO] 2018-10-24 04:21:39,530 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380099530
[INFO] 2018-10-24 04:21:39,531 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-e17955b9-4e0b-419b-b353-08b986a10b5b/userFiles-48943beb-dc07-46f5-9beb-b0a2d42f2d1b/packages.zip
[INFO] 2018-10-24 04:21:39,597 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:21:39,621 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31959.
[INFO] 2018-10-24 04:21:39,622 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:31959
[INFO] 2018-10-24 04:21:39,624 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:21:39,657 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 31959, None)
[INFO] 2018-10-24 04:21:39,661 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:31959 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 31959, None)
[INFO] 2018-10-24 04:21:39,664 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 31959, None)
[INFO] 2018-10-24 04:21:39,665 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 31959, None)
[INFO] 2018-10-24 04:21:39,924 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:21:39,924 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:21:40,446 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:21:41,263 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:21:41,276 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:21:41,289 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:21:41,300 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:21:41,301 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:21:41,313 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:21:41,320 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:21:41,336 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:21:41,338 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:21:41,340 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4af2640d-cd36-4e46-9283-136f7db85481
[INFO] 2018-10-24 04:21:41,341 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-e17955b9-4e0b-419b-b353-08b986a10b5b/pyspark-16ce423f-d9b3-4e98-b722-faf8c0728005
[INFO] 2018-10-24 04:21:41,342 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-e17955b9-4e0b-419b-b353-08b986a10b5b
[WARN] 2018-10-24 04:21:46,843 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:21:47,715 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:21:47,742 org.apache.spark.SparkContext logInfo - Submitted application: JB_STG_BOOKING_INCR
[INFO] 2018-10-24 04:21:47,877 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:21:47,877 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:21:47,877 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:21:47,878 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:21:47,890 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:21:48,149 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 28793.
[INFO] 2018-10-24 04:21:48,174 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:21:48,194 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:21:48,197 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:21:48,197 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:21:48,206 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-ca90d70f-77eb-4ec8-abae-733971821688
[INFO] 2018-10-24 04:21:48,224 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:21:48,238 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 04:21:48,454 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 04:21:48,515 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:21:48,637 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380108636
[INFO] 2018-10-24 04:21:48,639 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-c737a8d8-2df9-43b4-b50b-9ea89bd36401/userFiles-c59a82c2-1c39-451a-bea5-0fe1e653e423/etl_config.json
[INFO] 2018-10-24 04:21:48,654 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_STG_BOOKING_INCR.py at file:/home/spark/EBI_Project/jobs/SCH/JB_STG_BOOKING_INCR.py with timestamp 1540380108654
[INFO] 2018-10-24 04:21:48,655 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_STG_BOOKING_INCR.py to /tmp/spark-c737a8d8-2df9-43b4-b50b-9ea89bd36401/userFiles-c59a82c2-1c39-451a-bea5-0fe1e653e423/JB_STG_BOOKING_INCR.py
[INFO] 2018-10-24 04:21:48,660 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380108660
[INFO] 2018-10-24 04:21:48,660 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-c737a8d8-2df9-43b4-b50b-9ea89bd36401/userFiles-c59a82c2-1c39-451a-bea5-0fe1e653e423/packages.zip
[INFO] 2018-10-24 04:21:48,718 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:21:48,741 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 27138.
[INFO] 2018-10-24 04:21:48,742 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:27138
[INFO] 2018-10-24 04:21:48,744 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:21:48,772 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 27138, None)
[INFO] 2018-10-24 04:21:48,776 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:27138 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 27138, None)
[INFO] 2018-10-24 04:21:48,779 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 27138, None)
[INFO] 2018-10-24 04:21:48,780 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 27138, None)
[WARN] 2018-10-24 04:21:48,953 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:21:49,083 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:21:49,083 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:21:49,658 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:21:49,814 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:21:49,842 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE
[INFO] 2018-10-24 04:21:49,984 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:21:49,985 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:21:49,985 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:21:49,986 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:21:49,986 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:21:50,194 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 14880.
[INFO] 2018-10-24 04:21:50,220 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:21:50,240 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:21:50,244 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:21:50,244 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:21:50,254 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-1447f483-49db-4a8b-b2e7-2bc94445c8bd
[INFO] 2018-10-24 04:21:50,273 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:21:50,288 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:21:50,482 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:21:50,489 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:21:50,569 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:21:50,675 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380110674
[INFO] 2018-10-24 04:21:50,677 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-86b02565-b138-44b8-85ae-1b65578b19d1/userFiles-313023e1-2aef-4183-b2a8-bd36ec333605/etl_config.json
[INFO] 2018-10-24 04:21:50,691 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py with timestamp 1540380110691
[INFO] 2018-10-24 04:21:50,692 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE.py to /tmp/spark-86b02565-b138-44b8-85ae-1b65578b19d1/userFiles-313023e1-2aef-4183-b2a8-bd36ec333605/JB_WORK_INVOICE.py
[INFO] 2018-10-24 04:21:50,695 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380110695
[INFO] 2018-10-24 04:21:50,696 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-86b02565-b138-44b8-85ae-1b65578b19d1/userFiles-313023e1-2aef-4183-b2a8-bd36ec333605/packages.zip
[INFO] 2018-10-24 04:21:50,766 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:21:50,791 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 15825.
[INFO] 2018-10-24 04:21:50,793 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:15825
[INFO] 2018-10-24 04:21:50,795 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:21:50,829 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 15825, None)
[INFO] 2018-10-24 04:21:50,834 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:15825 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 15825, None)
[INFO] 2018-10-24 04:21:50,837 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 15825, None)
[INFO] 2018-10-24 04:21:50,838 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 15825, None)
[INFO] 2018-10-24 04:21:51,136 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:21:51,136 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:21:51,726 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:21:59,588 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:21:59,598 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:21:59,611 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:21:59,621 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:21:59,622 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:21:59,629 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:21:59,634 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:21:59,642 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:21:59,643 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:21:59,644 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f00f4141-2a0e-41c9-9529-a8477ba40a33
[INFO] 2018-10-24 04:21:59,645 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-86b02565-b138-44b8-85ae-1b65578b19d1/pyspark-a48b4fc8-0c0b-45bd-a2da-90f965bf9ece
[INFO] 2018-10-24 04:21:59,645 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-86b02565-b138-44b8-85ae-1b65578b19d1
[INFO] 2018-10-24 04:24:16,926 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:24:16,939 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:24:16,953 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:24:16,967 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:24:16,968 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:24:16,969 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:24:16,976 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:24:16,983 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:24:16,984 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:24:16,985 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-30bfed19-d9cf-4a01-bc9a-3ba76226a7f1
[INFO] 2018-10-24 04:24:16,985 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c737a8d8-2df9-43b4-b50b-9ea89bd36401/pyspark-0a93b4b9-fe7c-4601-8db6-cf6775874cfb
[INFO] 2018-10-24 04:24:16,986 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c737a8d8-2df9-43b4-b50b-9ea89bd36401
[WARN] 2018-10-24 04:31:56,635 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:31:57,413 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:31:57,440 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP_TRUNCATE
[INFO] 2018-10-24 04:31:57,616 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:31:57,616 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:31:57,616 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:31:57,617 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:31:57,617 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:31:57,858 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 26618.
[INFO] 2018-10-24 04:31:57,891 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:31:57,912 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:31:57,915 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:31:57,915 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:31:57,925 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-f693c4da-2b19-4d10-b478-0cfc4f435988
[INFO] 2018-10-24 04:31:57,943 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:31:57,957 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 04:31:58,141 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 04:31:58,205 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:31:58,347 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380718346
[INFO] 2018-10-24 04:31:58,349 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/userFiles-28ca25e9-2e0d-44fd-8050-eaef9ee21055/etl_config.json
[INFO] 2018-10-24 04:31:58,364 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540380718364
[INFO] 2018-10-24 04:31:58,364 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/userFiles-28ca25e9-2e0d-44fd-8050-eaef9ee21055/JB_Truncate_Partition.py
[INFO] 2018-10-24 04:31:58,369 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380718369
[INFO] 2018-10-24 04:31:58,370 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/userFiles-28ca25e9-2e0d-44fd-8050-eaef9ee21055/packages.zip
[INFO] 2018-10-24 04:31:58,444 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:31:58,471 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32891.
[INFO] 2018-10-24 04:31:58,472 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:32891
[INFO] 2018-10-24 04:31:58,474 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:31:58,511 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 32891, None)
[INFO] 2018-10-24 04:31:58,517 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:32891 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 32891, None)
[INFO] 2018-10-24 04:31:58,522 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 32891, None)
[INFO] 2018-10-24 04:31:58,523 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 32891, None)
[INFO] 2018-10-24 04:31:58,799 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:31:58,800 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:31:59,431 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:32:02,854 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 214.893324 ms
[INFO] 2018-10-24 04:32:03,010 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340
[INFO] 2018-10-24 04:32:03,037 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) with 1 output partitions
[INFO] 2018-10-24 04:32:03,038 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340)
[INFO] 2018-10-24 04:32:03,038 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 04:32:03,040 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 04:32:03,049 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340), which has no missing parents
[INFO] 2018-10-24 04:32:03,117 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 04:32:03,147 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 04:32:03,149 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:32891 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 04:32:03,159 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 04:32:03,184 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 04:32:03,185 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 04:32:03,248 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 04:32:03,266 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 04:32:03,271 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540380718364
[INFO] 2018-10-24 04:32:03,304 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/userFiles-28ca25e9-2e0d-44fd-8050-eaef9ee21055/JB_Truncate_Partition.py
[INFO] 2018-10-24 04:32:03,309 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380718346
[INFO] 2018-10-24 04:32:03,310 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/userFiles-28ca25e9-2e0d-44fd-8050-eaef9ee21055/etl_config.json
[INFO] 2018-10-24 04:32:03,315 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540380718369
[INFO] 2018-10-24 04:32:03,316 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/userFiles-28ca25e9-2e0d-44fd-8050-eaef9ee21055/packages.zip
[INFO] 2018-10-24 04:32:04,584 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 04:32:04,622 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 531, boot = 431, init = 99, finish = 1
[INFO] 2018-10-24 04:32:04,641 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1661 bytes result sent to driver
[INFO] 2018-10-24 04:32:04,661 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 1428 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 04:32:04,666 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 04:32:04,674 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) finished in 1.603 s
[INFO] 2018-10-24 04:32:04,682 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340, took 1.670703 s
[INFO] 2018-10-24 04:32:04,763 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341
[INFO] 2018-10-24 04:32:04,764 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) with 1 output partitions
[INFO] 2018-10-24 04:32:04,765 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341)
[INFO] 2018-10-24 04:32:04,765 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 04:32:04,765 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 04:32:04,766 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341), which has no missing parents
[INFO] 2018-10-24 04:32:04,773 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 04:32:04,775 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 04:32:04,776 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:32891 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 04:32:04,778 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 04:32:04,779 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 04:32:04,779 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 04:32:04,781 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 04:32:04,782 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 04:32:05,182 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 04:32:05,184 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 43, boot = -513, init = 556, finish = 0
[INFO] 2018-10-24 04:32:05,188 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
[INFO] 2018-10-24 04:32:05,192 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 411 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 04:32:05,193 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 04:32:05,195 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) finished in 0.425 s
[INFO] 2018-10-24 04:32:05,197 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341, took 0.433613 s
[INFO] 2018-10-24 04:32:05,535 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:32:05,549 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 04:32:05,565 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:32:05,591 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:32:05,592 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:32:05,599 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:32:05,604 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:32:05,616 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:32:05,617 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:32:05,619 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b
[INFO] 2018-10-24 04:32:05,620 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f016613b-70d2-44e8-962f-5dc0bd37572b/pyspark-6230a8a5-eac9-4681-a073-6e77c7784c17
[INFO] 2018-10-24 04:32:05,620 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d0361cb1-f79c-46c9-b7bf-76e33c99172e
[WARN] 2018-10-24 04:33:19,214 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:33:20,018 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:33:20,045 org.apache.spark.SparkContext logInfo - Submitted application: JB_STG_BOOKING_INCR
[INFO] 2018-10-24 04:33:20,338 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:33:20,339 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:33:20,339 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:33:20,339 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:33:20,340 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:33:20,557 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 32756.
[INFO] 2018-10-24 04:33:20,587 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:33:20,608 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:33:20,611 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:33:20,611 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:33:20,621 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-b67dfbc5-71fa-45e5-9735-81ca250fd404
[INFO] 2018-10-24 04:33:20,639 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:33:20,654 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 04:33:20,843 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 04:33:20,897 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[WARN] 2018-10-24 04:33:34,175 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:33:34,999 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:33:35,025 org.apache.spark.SparkContext logInfo - Submitted application: JB_DAY_FLAG_LOGIC_BOOKINGS_TRUNCATE
[INFO] 2018-10-24 04:33:35,172 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:33:35,173 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:33:35,173 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:33:35,174 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:33:35,185 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:33:35,391 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 22110.
[INFO] 2018-10-24 04:33:35,417 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:33:35,437 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:33:35,440 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:33:35,441 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:33:35,450 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-cdc27726-6755-45cb-b4ac-b15a86aba1b9
[INFO] 2018-10-24 04:33:35,468 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:33:35,482 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:33:35,655 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:33:35,664 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:33:35,716 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:33:35,811 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380815811
[INFO] 2018-10-24 04:33:35,813 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-70b1be8c-dd4d-49a0-8390-77b2411beb98/userFiles-1cae5661-d3cb-4ce3-8ae2-c123364d404e/etl_config.json
[INFO] 2018-10-24 04:33:35,825 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_LOGIC_BOOKINGS_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_LOGIC_BOOKINGS_TRUNCATE.py with timestamp 1540380815825
[INFO] 2018-10-24 04:33:35,825 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_LOGIC_BOOKINGS_TRUNCATE.py to /tmp/spark-70b1be8c-dd4d-49a0-8390-77b2411beb98/userFiles-1cae5661-d3cb-4ce3-8ae2-c123364d404e/JB_DAY_FLAG_LOGIC_BOOKINGS_TRUNCATE.py
[INFO] 2018-10-24 04:33:35,829 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380815829
[INFO] 2018-10-24 04:33:35,830 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-70b1be8c-dd4d-49a0-8390-77b2411beb98/userFiles-1cae5661-d3cb-4ce3-8ae2-c123364d404e/packages.zip
[INFO] 2018-10-24 04:33:35,896 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:33:35,925 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 16697.
[INFO] 2018-10-24 04:33:35,926 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:16697
[INFO] 2018-10-24 04:33:35,928 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:33:35,962 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 16697, None)
[INFO] 2018-10-24 04:33:35,966 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:16697 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 16697, None)
[INFO] 2018-10-24 04:33:35,968 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 16697, None)
[INFO] 2018-10-24 04:33:35,969 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 16697, None)
[INFO] 2018-10-24 04:33:36,278 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:33:36,279 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:33:36,848 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:33:37,608 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:33:37,618 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:33:37,631 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:33:37,641 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:33:37,642 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:33:37,652 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:33:37,657 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:33:37,667 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:33:37,668 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:33:37,670 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-70b1be8c-dd4d-49a0-8390-77b2411beb98
[INFO] 2018-10-24 04:33:37,671 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-70b1be8c-dd4d-49a0-8390-77b2411beb98/pyspark-b0de8561-e6b6-468f-adac-8eb0b9089630
[INFO] 2018-10-24 04:33:37,672 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-78aa4498-b53e-4519-b758-87ed46829c9f
[WARN] 2018-10-24 04:33:44,034 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:33:44,843 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:33:44,870 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP_TRUNCATE
[INFO] 2018-10-24 04:33:45,029 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:33:45,030 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:33:45,030 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:33:45,030 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:33:45,039 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:33:45,239 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 27072.
[INFO] 2018-10-24 04:33:45,265 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:33:45,286 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:33:45,289 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:33:45,289 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:33:45,299 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-2e733391-a15b-4ab3-b0fc-4354530f3eb6
[INFO] 2018-10-24 04:33:45,317 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:33:45,331 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:33:45,504 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:33:45,510 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:33:45,566 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:33:45,673 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380825673
[INFO] 2018-10-24 04:33:45,675 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/userFiles-9236afe1-dc16-440f-b4b3-0d60faf1ec6d/etl_config.json
[INFO] 2018-10-24 04:33:45,687 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540380825687
[INFO] 2018-10-24 04:33:45,688 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/userFiles-9236afe1-dc16-440f-b4b3-0d60faf1ec6d/JB_Truncate_Partition.py
[INFO] 2018-10-24 04:33:45,691 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540380825691
[INFO] 2018-10-24 04:33:45,692 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/userFiles-9236afe1-dc16-440f-b4b3-0d60faf1ec6d/packages.zip
[INFO] 2018-10-24 04:33:45,759 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:33:45,784 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 25593.
[INFO] 2018-10-24 04:33:45,785 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:25593
[INFO] 2018-10-24 04:33:45,787 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:33:45,823 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 25593, None)
[INFO] 2018-10-24 04:33:45,830 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:25593 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 25593, None)
[INFO] 2018-10-24 04:33:45,835 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 25593, None)
[INFO] 2018-10-24 04:33:45,835 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 25593, None)
[INFO] 2018-10-24 04:33:46,136 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:33:46,136 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:33:46,753 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:33:49,854 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 210.474116 ms
[INFO] 2018-10-24 04:33:50,017 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340
[INFO] 2018-10-24 04:33:50,038 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) with 1 output partitions
[INFO] 2018-10-24 04:33:50,038 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340)
[INFO] 2018-10-24 04:33:50,039 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 04:33:50,041 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 04:33:50,049 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340), which has no missing parents
[INFO] 2018-10-24 04:33:50,124 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 04:33:50,164 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 04:33:50,168 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:25593 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 04:33:50,171 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 04:33:50,185 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 04:33:50,186 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 04:33:50,237 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 04:33:50,250 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 04:33:50,254 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540380825687
[INFO] 2018-10-24 04:33:50,285 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/userFiles-9236afe1-dc16-440f-b4b3-0d60faf1ec6d/JB_Truncate_Partition.py
[INFO] 2018-10-24 04:33:50,292 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540380825673
[INFO] 2018-10-24 04:33:50,293 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/userFiles-9236afe1-dc16-440f-b4b3-0d60faf1ec6d/etl_config.json
[INFO] 2018-10-24 04:33:50,299 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540380825691
[INFO] 2018-10-24 04:33:50,301 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/userFiles-9236afe1-dc16-440f-b4b3-0d60faf1ec6d/packages.zip
[INFO] 2018-10-24 04:33:51,153 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 04:33:51,200 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 506, boot = 381, init = 124, finish = 1
[INFO] 2018-10-24 04:33:51,227 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1661 bytes result sent to driver
[INFO] 2018-10-24 04:33:51,244 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 1022 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 04:33:51,248 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 04:33:51,257 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) finished in 1.187 s
[INFO] 2018-10-24 04:33:51,263 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340, took 1.245155 s
[INFO] 2018-10-24 04:33:51,338 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341
[INFO] 2018-10-24 04:33:51,339 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) with 1 output partitions
[INFO] 2018-10-24 04:33:51,339 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341)
[INFO] 2018-10-24 04:33:51,339 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 04:33:51,340 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 04:33:51,340 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341), which has no missing parents
[INFO] 2018-10-24 04:33:51,344 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 04:33:51,346 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 04:33:51,347 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:25593 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 04:33:51,349 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 04:33:51,350 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 04:33:51,350 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 04:33:51,352 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 04:33:51,352 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 04:33:51,677 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 04:33:51,679 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 47, boot = -426, init = 473, finish = 0
[INFO] 2018-10-24 04:33:51,680 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
[INFO] 2018-10-24 04:33:51,683 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 332 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 04:33:51,684 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 04:33:51,685 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) finished in 0.344 s
[INFO] 2018-10-24 04:33:51,686 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341, took 0.347654 s
[INFO] 2018-10-24 04:33:52,070 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:33:52,081 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:33:52,096 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:33:52,106 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:33:52,107 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:33:52,113 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:33:52,117 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:33:52,125 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:33:52,127 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:33:52,129 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed
[INFO] 2018-10-24 04:33:52,131 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-82bd89c2-43b2-4d87-8460-2b14241d88eb
[INFO] 2018-10-24 04:33:52,132 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-db23b837-aa97-473d-bc94-692b0af358ed/pyspark-d832df16-ceb7-4a1b-a70d-91572571bb3d
[WARN] 2018-10-24 04:37:42,825 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:37:43,684 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:37:43,711 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP_TRUNCATE
[INFO] 2018-10-24 04:37:43,842 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:37:43,843 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:37:43,843 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:37:43,843 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:37:43,844 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:37:44,062 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 26216.
[INFO] 2018-10-24 04:37:44,089 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:37:44,110 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:37:44,113 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:37:44,114 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:37:44,123 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-2b79c471-d205-4723-9581-a712328ffe9a
[INFO] 2018-10-24 04:37:44,143 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:37:44,159 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:37:44,364 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:37:44,371 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:37:44,431 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:37:44,542 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540381064542
[INFO] 2018-10-24 04:37:44,544 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/userFiles-942b3940-bba1-4323-9a60-52be8c6c92ca/etl_config.json
[INFO] 2018-10-24 04:37:44,557 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540381064557
[INFO] 2018-10-24 04:37:44,557 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/userFiles-942b3940-bba1-4323-9a60-52be8c6c92ca/JB_Truncate_Partition.py
[INFO] 2018-10-24 04:37:44,561 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540381064561
[INFO] 2018-10-24 04:37:44,562 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/userFiles-942b3940-bba1-4323-9a60-52be8c6c92ca/packages.zip
[INFO] 2018-10-24 04:37:44,634 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:37:44,659 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 18303.
[INFO] 2018-10-24 04:37:44,660 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:18303
[INFO] 2018-10-24 04:37:44,661 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:37:44,696 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 18303, None)
[INFO] 2018-10-24 04:37:44,703 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:18303 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 18303, None)
[INFO] 2018-10-24 04:37:44,708 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 18303, None)
[INFO] 2018-10-24 04:37:44,709 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 18303, None)
[INFO] 2018-10-24 04:37:45,014 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:37:45,014 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:37:45,601 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:37:48,799 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 246.611922 ms
[INFO] 2018-10-24 04:37:48,980 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340
[INFO] 2018-10-24 04:37:49,005 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) with 1 output partitions
[INFO] 2018-10-24 04:37:49,006 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340)
[INFO] 2018-10-24 04:37:49,007 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 04:37:49,009 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 04:37:49,018 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340), which has no missing parents
[INFO] 2018-10-24 04:37:49,100 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 04:37:49,143 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 04:37:49,147 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:18303 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 04:37:49,150 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 04:37:49,167 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 04:37:49,168 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 04:37:49,228 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 04:37:49,243 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 04:37:49,249 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540381064557
[INFO] 2018-10-24 04:37:49,282 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/userFiles-942b3940-bba1-4323-9a60-52be8c6c92ca/JB_Truncate_Partition.py
[INFO] 2018-10-24 04:37:49,286 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540381064542
[INFO] 2018-10-24 04:37:49,287 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/userFiles-942b3940-bba1-4323-9a60-52be8c6c92ca/etl_config.json
[INFO] 2018-10-24 04:37:49,293 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540381064561
[INFO] 2018-10-24 04:37:49,295 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/userFiles-942b3940-bba1-4323-9a60-52be8c6c92ca/packages.zip
[INFO] 2018-10-24 04:37:50,140 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 04:37:50,184 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 522, boot = 422, init = 99, finish = 1
[INFO] 2018-10-24 04:37:50,204 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1661 bytes result sent to driver
[INFO] 2018-10-24 04:37:50,218 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 1007 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 04:37:50,223 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 04:37:50,232 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) finished in 1.191 s
[INFO] 2018-10-24 04:37:50,237 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340, took 1.256733 s
[INFO] 2018-10-24 04:37:50,310 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341
[INFO] 2018-10-24 04:37:50,312 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) with 1 output partitions
[INFO] 2018-10-24 04:37:50,312 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341)
[INFO] 2018-10-24 04:37:50,312 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 04:37:50,312 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 04:37:50,313 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341), which has no missing parents
[INFO] 2018-10-24 04:37:50,316 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 04:37:50,318 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 04:37:50,319 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:18303 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 04:37:50,321 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 04:37:50,322 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 04:37:50,322 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 04:37:50,324 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 04:37:50,325 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 04:37:50,653 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 04:37:50,656 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 49, boot = -418, init = 467, finish = 0
[INFO] 2018-10-24 04:37:50,660 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
[INFO] 2018-10-24 04:37:50,662 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 338 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 04:37:50,663 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 04:37:50,665 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) finished in 0.351 s
[INFO] 2018-10-24 04:37:50,666 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341, took 0.355410 s
[INFO] 2018-10-24 04:37:51,007 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:37:51,021 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:37:51,037 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:37:51,047 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:37:51,047 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:37:51,058 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:37:51,063 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:37:51,071 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:37:51,072 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:37:51,073 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-114ce3ef-f70d-45c8-8944-e8c25e16366b
[INFO] 2018-10-24 04:37:51,074 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7
[INFO] 2018-10-24 04:37:51,074 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-95ac3358-6e4d-475e-8c32-8ffaec0b26b7/pyspark-e0075d85-6f47-4425-9a85-6348f9fe4b2b
[WARN] 2018-10-24 04:42:29,098 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:42:30,002 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:42:30,028 org.apache.spark.SparkContext logInfo - Submitted application: JB_DAY_FLAG_BOOKINGS
[INFO] 2018-10-24 04:42:30,260 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:42:30,260 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:42:30,261 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:42:30,261 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:42:30,261 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:42:30,471 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 15721.
[INFO] 2018-10-24 04:42:30,497 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:42:30,517 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:42:30,521 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:42:30,521 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:42:30,530 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-c03a9314-7a6a-41a2-8e33-2bd9e72b2d89
[INFO] 2018-10-24 04:42:30,549 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:42:30,563 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:42:30,745 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:42:30,751 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:42:30,805 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:42:30,901 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540381350901
[INFO] 2018-10-24 04:42:30,903 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-46cd065a-c67f-44f3-9d41-26d6a9af4c9a/userFiles-3a5e6f10-7ca0-45b8-8fd6-bf6aa2fe6135/etl_config.json
[INFO] 2018-10-24 04:42:30,917 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py at file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py with timestamp 1540381350917
[INFO] 2018-10-24 04:42:30,918 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py to /tmp/spark-46cd065a-c67f-44f3-9d41-26d6a9af4c9a/userFiles-3a5e6f10-7ca0-45b8-8fd6-bf6aa2fe6135/JB_DAY_FLAG_BOOKINGS.py
[INFO] 2018-10-24 04:42:30,923 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540381350923
[INFO] 2018-10-24 04:42:30,923 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-46cd065a-c67f-44f3-9d41-26d6a9af4c9a/userFiles-3a5e6f10-7ca0-45b8-8fd6-bf6aa2fe6135/packages.zip
[INFO] 2018-10-24 04:42:31,001 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:42:31,027 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 11496.
[INFO] 2018-10-24 04:42:31,028 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:11496
[INFO] 2018-10-24 04:42:31,030 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:42:31,061 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 11496, None)
[INFO] 2018-10-24 04:42:31,066 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:11496 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 11496, None)
[INFO] 2018-10-24 04:42:31,069 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 11496, None)
[INFO] 2018-10-24 04:42:31,069 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 11496, None)
[INFO] 2018-10-24 04:42:31,352 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:42:31,353 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:42:31,923 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:42:32,285 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:42:32,299 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:42:32,311 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:42:32,321 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:42:32,322 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:42:32,333 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:42:32,339 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:42:32,353 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:42:32,353 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:42:32,354 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-5f480bd3-9543-487d-b007-96623a73c301
[INFO] 2018-10-24 04:42:32,355 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-46cd065a-c67f-44f3-9d41-26d6a9af4c9a
[INFO] 2018-10-24 04:42:32,355 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-46cd065a-c67f-44f3-9d41-26d6a9af4c9a/pyspark-f16c482b-ef3a-4525-a786-f29206983a7c
[WARN] 2018-10-24 04:43:23,536 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:43:24,348 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:43:24,375 org.apache.spark.SparkContext logInfo - Submitted application: JB_DAY_FLAG_BOOKINGS
[INFO] 2018-10-24 04:43:24,585 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:43:24,585 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:43:24,585 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:43:24,586 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:43:24,596 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:43:24,797 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 36932.
[INFO] 2018-10-24 04:43:24,823 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:43:24,843 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:43:24,846 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:43:24,847 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:43:24,856 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-1dd153a8-f5fc-42e5-aa94-4ea76582a33b
[INFO] 2018-10-24 04:43:24,874 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:43:24,889 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:43:25,082 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:43:25,089 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:43:25,152 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:43:25,262 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540381405261
[INFO] 2018-10-24 04:43:25,264 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-19dcc8f0-0482-4241-987d-b0f919a93f52/userFiles-35a62a5a-32db-4493-ac3e-ec5415a20186/etl_config.json
[INFO] 2018-10-24 04:43:25,278 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py at file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py with timestamp 1540381405278
[INFO] 2018-10-24 04:43:25,279 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py to /tmp/spark-19dcc8f0-0482-4241-987d-b0f919a93f52/userFiles-35a62a5a-32db-4493-ac3e-ec5415a20186/JB_DAY_FLAG_BOOKINGS.py
[INFO] 2018-10-24 04:43:25,284 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540381405284
[INFO] 2018-10-24 04:43:25,285 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-19dcc8f0-0482-4241-987d-b0f919a93f52/userFiles-35a62a5a-32db-4493-ac3e-ec5415a20186/packages.zip
[INFO] 2018-10-24 04:43:25,356 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:43:25,385 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14186.
[INFO] 2018-10-24 04:43:25,386 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:14186
[INFO] 2018-10-24 04:43:25,387 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:43:25,424 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 14186, None)
[INFO] 2018-10-24 04:43:25,431 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:14186 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 14186, None)
[INFO] 2018-10-24 04:43:25,435 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 14186, None)
[INFO] 2018-10-24 04:43:25,437 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 14186, None)
[INFO] 2018-10-24 04:43:25,742 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:43:25,743 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:43:26,336 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:43:26,706 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:43:26,716 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:43:26,733 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:43:26,742 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:43:26,742 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:43:26,750 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:43:26,756 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:43:26,764 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:43:26,766 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:43:26,768 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-19dcc8f0-0482-4241-987d-b0f919a93f52/pyspark-d633a90a-71c4-489e-83b1-3750d68f2dc3
[INFO] 2018-10-24 04:43:26,769 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-facdbf03-8692-46bc-9ed4-1317320dc655
[INFO] 2018-10-24 04:43:26,769 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-19dcc8f0-0482-4241-987d-b0f919a93f52
[WARN] 2018-10-24 04:45:05,196 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 04:45:06,073 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 04:45:06,099 org.apache.spark.SparkContext logInfo - Submitted application: JB_DAY_FLAG_BOOKINGS
[INFO] 2018-10-24 04:45:06,316 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 04:45:06,316 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 04:45:06,317 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 04:45:06,317 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 04:45:06,317 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 04:45:06,565 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 19120.
[INFO] 2018-10-24 04:45:06,597 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 04:45:06,620 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 04:45:06,624 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 04:45:06,624 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 04:45:06,635 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-de9fbffe-eeff-418f-923a-8516bb21eef9
[INFO] 2018-10-24 04:45:06,653 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 04:45:06,667 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 04:45:06,840 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 04:45:06,846 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 04:45:06,900 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:45:06,991 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540381506991
[INFO] 2018-10-24 04:45:06,993 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-87b4b573-b671-4509-b066-04d2bbc55e78/userFiles-9deed439-0d68-43a2-92db-c3f989d17d68/etl_config.json
[INFO] 2018-10-24 04:45:07,007 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py at file:/home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py with timestamp 1540381507007
[INFO] 2018-10-24 04:45:07,007 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_DAY_FLAG_BOOKINGS.py to /tmp/spark-87b4b573-b671-4509-b066-04d2bbc55e78/userFiles-9deed439-0d68-43a2-92db-c3f989d17d68/JB_DAY_FLAG_BOOKINGS.py
[INFO] 2018-10-24 04:45:07,011 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540381507011
[INFO] 2018-10-24 04:45:07,012 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-87b4b573-b671-4509-b066-04d2bbc55e78/userFiles-9deed439-0d68-43a2-92db-c3f989d17d68/packages.zip
[INFO] 2018-10-24 04:45:07,081 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 04:45:07,111 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12101.
[INFO] 2018-10-24 04:45:07,112 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:12101
[INFO] 2018-10-24 04:45:07,115 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 04:45:07,160 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 12101, None)
[INFO] 2018-10-24 04:45:07,166 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:12101 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 12101, None)
[INFO] 2018-10-24 04:45:07,171 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 12101, None)
[INFO] 2018-10-24 04:45:07,172 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 12101, None)
[INFO] 2018-10-24 04:45:07,474 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 04:45:07,475 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 04:45:07,972 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 04:45:08,699 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 04:45:08,710 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 04:45:08,723 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 04:45:08,737 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 04:45:08,737 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 04:45:08,745 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 04:45:08,751 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 04:45:08,766 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 04:45:08,767 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 04:45:08,768 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-87b4b573-b671-4509-b066-04d2bbc55e78
[INFO] 2018-10-24 04:45:08,771 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-034f7fa6-96d6-4b2b-9050-d42a373509ec
[INFO] 2018-10-24 04:45:08,771 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-87b4b573-b671-4509-b066-04d2bbc55e78/pyspark-a3d578a0-7907-4f07-af97-f6f499497cc9
[WARN] 2018-10-24 05:13:47,268 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 05:13:48,106 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 05:13:48,133 org.apache.spark.SparkContext logInfo - Submitted application: JB_BOOKINGS_REJ_TRUNCATE
[INFO] 2018-10-24 05:13:48,298 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 05:13:48,299 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 05:13:48,299 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 05:13:48,300 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 05:13:48,300 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 05:13:48,559 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 28186.
[INFO] 2018-10-24 05:13:48,589 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 05:13:48,612 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 05:13:48,616 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 05:13:48,617 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 05:13:48,628 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-75b50012-45d0-4423-a36c-f9fa78467c6a
[INFO] 2018-10-24 05:13:48,649 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 05:13:48,666 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 05:13:48,855 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 05:13:48,862 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 05:13:48,929 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 05:13:49,035 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540383229034
[INFO] 2018-10-24 05:13:49,037 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-40c7ef4f-aaea-4f8c-ae7e-1637b06ea2a8/userFiles-2ec1acda-e5ae-4cb6-91b3-fdf3b1b8e7e3/etl_config.json
[INFO] 2018-10-24 05:13:49,053 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_BOOKINGS_REJ_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_BOOKINGS_REJ_TRUNCATE.py with timestamp 1540383229053
[INFO] 2018-10-24 05:13:49,054 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_BOOKINGS_REJ_TRUNCATE.py to /tmp/spark-40c7ef4f-aaea-4f8c-ae7e-1637b06ea2a8/userFiles-2ec1acda-e5ae-4cb6-91b3-fdf3b1b8e7e3/JB_BOOKINGS_REJ_TRUNCATE.py
[INFO] 2018-10-24 05:13:49,058 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540383229058
[INFO] 2018-10-24 05:13:49,059 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-40c7ef4f-aaea-4f8c-ae7e-1637b06ea2a8/userFiles-2ec1acda-e5ae-4cb6-91b3-fdf3b1b8e7e3/packages.zip
[INFO] 2018-10-24 05:13:49,132 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 05:13:49,156 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 17313.
[INFO] 2018-10-24 05:13:49,157 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:17313
[INFO] 2018-10-24 05:13:49,159 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 05:13:49,193 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 17313, None)
[INFO] 2018-10-24 05:13:49,199 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:17313 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 17313, None)
[INFO] 2018-10-24 05:13:49,203 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 17313, None)
[INFO] 2018-10-24 05:13:49,203 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 17313, None)
[INFO] 2018-10-24 05:13:49,493 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 05:13:49,493 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 05:13:50,017 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 05:13:50,452 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 05:13:50,462 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 05:13:50,475 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 05:13:50,484 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 05:13:50,485 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 05:13:50,492 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 05:13:50,498 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 05:13:50,505 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 05:13:50,506 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 05:13:50,507 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4288f60e-ea69-4a70-aa8d-490964a0f774
[INFO] 2018-10-24 05:13:50,508 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-40c7ef4f-aaea-4f8c-ae7e-1637b06ea2a8
[INFO] 2018-10-24 05:13:50,508 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-40c7ef4f-aaea-4f8c-ae7e-1637b06ea2a8/pyspark-3ec339cb-2ce0-4188-94ca-fa69c81e2fcc
[WARN] 2018-10-24 05:13:59,860 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 05:14:00,267 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 05:14:00,269 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-23c560ae-6c06-4fea-bddd-92bc2bccede6
[WARN] 2018-10-24 05:14:19,034 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 05:14:19,878 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 05:14:19,905 org.apache.spark.SparkContext logInfo - Submitted application: JB_INVOICE_TIER_LOAD
[INFO] 2018-10-24 05:14:20,047 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 05:14:20,048 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 05:14:20,048 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 05:14:20,049 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 05:14:20,056 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 05:14:20,260 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 16252.
[INFO] 2018-10-24 05:14:20,285 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 05:14:20,305 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 05:14:20,308 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 05:14:20,309 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 05:14:20,318 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-513ea385-0e1a-4ab3-870f-2adefe9204d0
[INFO] 2018-10-24 05:14:20,336 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 05:14:20,351 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[WARN] 2018-10-24 05:14:20,529 org.apache.spark.util.Utils logWarning - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[INFO] 2018-10-24 05:14:20,535 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4041.
[INFO] 2018-10-24 05:14:20,596 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 05:14:20,693 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540383260692
[INFO] 2018-10-24 05:14:20,695 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-3f505da3-1d1d-440a-9697-c207c30dd9ae/userFiles-9e326980-88a7-4f7c-8efd-fccb9de4efbe/etl_config.json
[INFO] 2018-10-24 05:14:20,707 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py at file:/home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py with timestamp 1540383260707
[INFO] 2018-10-24 05:14:20,707 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py to /tmp/spark-3f505da3-1d1d-440a-9697-c207c30dd9ae/userFiles-9e326980-88a7-4f7c-8efd-fccb9de4efbe/JB_INVOICE_TIER_LOAD.py
[INFO] 2018-10-24 05:14:20,712 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540383260712
[INFO] 2018-10-24 05:14:20,712 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-3f505da3-1d1d-440a-9697-c207c30dd9ae/userFiles-9e326980-88a7-4f7c-8efd-fccb9de4efbe/packages.zip
[INFO] 2018-10-24 05:14:20,776 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 05:14:20,800 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36376.
[INFO] 2018-10-24 05:14:20,801 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:36376
[INFO] 2018-10-24 05:14:20,803 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 05:14:20,837 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 36376, None)
[INFO] 2018-10-24 05:14:20,841 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:36376 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 36376, None)
[INFO] 2018-10-24 05:14:20,844 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 36376, None)
[INFO] 2018-10-24 05:14:20,844 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 36376, None)
[INFO] 2018-10-24 05:14:21,128 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 05:14:21,129 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 05:14:21,726 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 05:14:50,819 org.apache.spark.storage.DiskBlockManager logInfo - Shutdown hook called
[INFO] 2018-10-24 05:14:50,832 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 05:14:50,833 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-832209b1-3fd7-42d3-8d2f-b8ee47f1fbfd
[INFO] 2018-10-24 05:14:50,834 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4ef45436-e36c-405f-9e49-92f7b4133328
[INFO] 2018-10-24 05:14:50,835 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4ef45436-e36c-405f-9e49-92f7b4133328/userFiles-b9ca7dd8-e84e-4978-a59d-3993c1a65da6
[INFO] 2018-10-24 05:17:32,441 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 05:17:32,453 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4041
[INFO] 2018-10-24 05:17:32,466 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 05:17:32,481 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 05:17:32,482 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 05:17:32,483 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 05:17:32,490 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 05:17:32,498 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 05:17:32,499 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 05:17:32,501 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-3f505da3-1d1d-440a-9697-c207c30dd9ae/pyspark-d1b3fdfa-8401-48a2-94c3-38ff420df18c
[INFO] 2018-10-24 05:17:32,501 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-3f505da3-1d1d-440a-9697-c207c30dd9ae
[INFO] 2018-10-24 05:17:32,501 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-46e0cf78-c748-426e-b95d-440a447edb73
[WARN] 2018-10-24 05:22:44,775 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 05:22:45,608 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 05:22:45,633 org.apache.spark.SparkContext logInfo - Submitted application: JB_INVOICE_TIER_LOAD
[INFO] 2018-10-24 05:22:45,811 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 05:22:45,812 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 05:22:45,812 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 05:22:45,812 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 05:22:45,813 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 05:22:46,071 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 29559.
[INFO] 2018-10-24 05:22:46,100 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 05:22:46,121 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 05:22:46,125 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 05:22:46,125 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 05:22:46,135 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-f1d81d16-1d33-4d0d-81d1-661fe1a4b0b3
[INFO] 2018-10-24 05:22:46,155 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 05:22:46,171 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 05:22:46,366 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 05:22:46,425 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 05:22:46,524 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540383766524
[INFO] 2018-10-24 05:22:46,526 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/userFiles-11cb0e8e-6542-4306-9313-7623e208050c/etl_config.json
[INFO] 2018-10-24 05:22:46,542 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py at file:/home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py with timestamp 1540383766542
[INFO] 2018-10-24 05:22:46,543 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py to /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/userFiles-11cb0e8e-6542-4306-9313-7623e208050c/JB_INVOICE_TIER_LOAD.py
[INFO] 2018-10-24 05:22:46,548 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540383766548
[INFO] 2018-10-24 05:22:46,549 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/userFiles-11cb0e8e-6542-4306-9313-7623e208050c/packages.zip
[INFO] 2018-10-24 05:22:46,620 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 05:22:46,650 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31020.
[INFO] 2018-10-24 05:22:46,651 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:31020
[INFO] 2018-10-24 05:22:46,653 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 05:22:46,687 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 31020, None)
[INFO] 2018-10-24 05:22:46,692 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:31020 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 31020, None)
[INFO] 2018-10-24 05:22:46,695 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 31020, None)
[INFO] 2018-10-24 05:22:46,696 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 31020, None)
[INFO] 2018-10-24 05:22:46,993 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 05:22:46,993 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 05:22:47,607 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 05:22:50,970 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 218.282827 ms
[INFO] 2018-10-24 05:22:51,161 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340
[INFO] 2018-10-24 05:22:51,188 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) with 1 output partitions
[INFO] 2018-10-24 05:22:51,189 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340)
[INFO] 2018-10-24 05:22:51,190 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 05:22:51,192 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 05:22:51,203 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340), which has no missing parents
[INFO] 2018-10-24 05:22:51,286 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 05:22:51,324 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 05:22:51,328 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:31020 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 05:22:51,332 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 05:22:51,349 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 05:22:51,351 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 05:22:51,410 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 05:22:51,425 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 05:22:51,433 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540383766524
[INFO] 2018-10-24 05:22:51,466 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/userFiles-11cb0e8e-6542-4306-9313-7623e208050c/etl_config.json
[INFO] 2018-10-24 05:22:51,471 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540383766548
[INFO] 2018-10-24 05:22:51,473 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/userFiles-11cb0e8e-6542-4306-9313-7623e208050c/packages.zip
[INFO] 2018-10-24 05:22:51,478 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py with timestamp 1540383766542
[INFO] 2018-10-24 05:22:51,479 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_INVOICE_TIER_LOAD.py has been previously copied to /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/userFiles-11cb0e8e-6542-4306-9313-7623e208050c/JB_INVOICE_TIER_LOAD.py
[INFO] 2018-10-24 05:22:52,404 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 05:22:52,446 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 577, boot = 462, init = 115, finish = 0
[INFO] 2018-10-24 05:22:52,466 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1661 bytes result sent to driver
[INFO] 2018-10-24 05:22:52,481 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 1084 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 05:22:52,485 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 05:22:52,498 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) finished in 1.269 s
[INFO] 2018-10-24 05:22:52,505 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340, took 1.343556 s
[INFO] 2018-10-24 05:22:52,575 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341
[INFO] 2018-10-24 05:22:52,578 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) with 1 output partitions
[INFO] 2018-10-24 05:22:52,578 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341)
[INFO] 2018-10-24 05:22:52,578 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 05:22:52,579 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 05:22:52,579 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341), which has no missing parents
[INFO] 2018-10-24 05:22:52,585 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 05:22:52,588 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 05:22:52,590 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:31020 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 05:22:52,592 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 05:22:52,593 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 05:22:52,593 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 05:22:52,595 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 05:22:52,596 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 05:22:52,930 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 05:22:52,932 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 62, boot = -416, init = 478, finish = 0
[INFO] 2018-10-24 05:22:52,936 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
[INFO] 2018-10-24 05:22:52,940 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 345 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 05:22:52,940 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 05:22:52,943 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) finished in 0.361 s
[INFO] 2018-10-24 05:22:52,944 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341, took 0.367813 s
[INFO] 2018-10-24 05:24:34,720 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 05:24:34,731 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 05:24:34,749 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 05:24:34,764 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 05:24:34,765 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 05:24:34,766 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 05:24:34,771 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 05:24:34,777 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 05:24:34,778 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 05:24:34,779 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef
[INFO] 2018-10-24 05:24:34,779 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-024df3f8-2c79-4ae9-a73d-ccc3727fd2ef/pyspark-1935c07c-0c7f-43af-9644-03f460d666a3
[INFO] 2018-10-24 05:24:34,780 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-979aefc5-76fa-4054-adb2-71c2fe550718
[WARN] 2018-10-24 08:03:36,228 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 08:03:37,035 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 08:03:37,062 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP_TRUNCATE
[INFO] 2018-10-24 08:03:37,226 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 08:03:37,226 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 08:03:37,226 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 08:03:37,227 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 08:03:37,227 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 08:03:37,468 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 31232.
[INFO] 2018-10-24 08:03:37,498 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 08:03:37,520 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 08:03:37,524 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 08:03:37,525 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 08:03:37,536 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-5a534569-4b9d-4eda-8395-cc5dc43f2559
[INFO] 2018-10-24 08:03:37,556 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 08:03:37,572 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 08:03:37,760 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 08:03:37,813 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 08:03:37,907 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540393417907
[INFO] 2018-10-24 08:03:37,909 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-684f073f-3baa-40c0-b159-babd2bba722e/userFiles-7037de34-2c59-41f7-9ea5-9741a380e888/etl_config.json
[INFO] 2018-10-24 08:03:37,923 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py with timestamp 1540393417923
[INFO] 2018-10-24 08:03:37,924 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py to /tmp/spark-684f073f-3baa-40c0-b159-babd2bba722e/userFiles-7037de34-2c59-41f7-9ea5-9741a380e888/JB_WORK_INVOICE_DATAPREP_TRUNCATE.py
[INFO] 2018-10-24 08:03:37,928 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540393417928
[INFO] 2018-10-24 08:03:37,928 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-684f073f-3baa-40c0-b159-babd2bba722e/userFiles-7037de34-2c59-41f7-9ea5-9741a380e888/packages.zip
[INFO] 2018-10-24 08:03:37,996 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 08:03:38,021 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 21269.
[INFO] 2018-10-24 08:03:38,022 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:21269
[INFO] 2018-10-24 08:03:38,024 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 08:03:38,057 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 21269, None)
[INFO] 2018-10-24 08:03:38,064 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:21269 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 21269, None)
[INFO] 2018-10-24 08:03:38,069 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 21269, None)
[INFO] 2018-10-24 08:03:38,069 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 21269, None)
[INFO] 2018-10-24 08:03:38,382 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 08:03:38,382 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 08:03:38,989 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 08:03:39,724 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 08:03:39,735 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 08:03:39,749 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 08:03:39,759 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 08:03:39,759 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 08:03:39,767 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 08:03:39,771 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 08:03:39,783 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 08:03:39,783 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 08:03:39,785 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-684f073f-3baa-40c0-b159-babd2bba722e/pyspark-73054ebd-1ff0-4629-b912-67340d3ca78c
[INFO] 2018-10-24 08:03:39,785 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-684f073f-3baa-40c0-b159-babd2bba722e
[INFO] 2018-10-24 08:03:39,786 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-aae55a20-fcbf-4910-bf5c-00e85d967b0b
[WARN] 2018-10-24 08:04:00,785 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 08:04:01,583 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 08:04:01,611 org.apache.spark.SparkContext logInfo - Submitted application: JB_WORK_INVOICE_DATAPREP
[INFO] 2018-10-24 08:04:01,817 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 08:04:01,817 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 08:04:01,818 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 08:04:01,818 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 08:04:01,818 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 08:04:02,026 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 35453.
[INFO] 2018-10-24 08:04:02,053 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 08:04:02,073 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 08:04:02,076 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 08:04:02,077 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 08:04:02,086 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-f2cd864b-1cec-42b0-8ec1-2fe2cadeeeca
[INFO] 2018-10-24 08:04:02,104 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 08:04:02,125 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 08:04:02,338 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 08:04:02,397 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 08:04:02,495 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540393442495
[INFO] 2018-10-24 08:04:02,497 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/userFiles-965f666b-5193-4f57-bad5-003efd0a9966/etl_config.json
[INFO] 2018-10-24 08:04:02,510 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py at file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py with timestamp 1540393442510
[INFO] 2018-10-24 08:04:02,511 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py to /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/userFiles-965f666b-5193-4f57-bad5-003efd0a9966/JB_WORK_INVOICE_DATAPREP.py
[INFO] 2018-10-24 08:04:02,515 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540393442515
[INFO] 2018-10-24 08:04:02,515 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/userFiles-965f666b-5193-4f57-bad5-003efd0a9966/packages.zip
[INFO] 2018-10-24 08:04:02,585 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 08:04:02,614 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 16592.
[INFO] 2018-10-24 08:04:02,615 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:16592
[INFO] 2018-10-24 08:04:02,617 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 08:04:02,652 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 16592, None)
[INFO] 2018-10-24 08:04:02,658 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:16592 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 16592, None)
[INFO] 2018-10-24 08:04:02,661 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 16592, None)
[INFO] 2018-10-24 08:04:02,662 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 16592, None)
[INFO] 2018-10-24 08:04:02,961 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 08:04:02,961 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 08:04:03,469 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 08:04:06,464 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 249.303855 ms
[INFO] 2018-10-24 08:04:06,645 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340
[INFO] 2018-10-24 08:04:06,667 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) with 1 output partitions
[INFO] 2018-10-24 08:04:06,667 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340)
[INFO] 2018-10-24 08:04:06,668 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 08:04:06,670 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 08:04:06,683 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340), which has no missing parents
[INFO] 2018-10-24 08:04:06,759 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 08:04:06,795 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 08:04:06,799 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:16592 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 08:04:06,802 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 08:04:06,817 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 08:04:06,818 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 08:04:06,865 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 08:04:06,882 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 08:04:06,891 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540393442495
[INFO] 2018-10-24 08:04:06,925 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/userFiles-965f666b-5193-4f57-bad5-003efd0a9966/etl_config.json
[INFO] 2018-10-24 08:04:06,931 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py with timestamp 1540393442510
[INFO] 2018-10-24 08:04:06,934 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_WORK_INVOICE_DATAPREP.py has been previously copied to /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/userFiles-965f666b-5193-4f57-bad5-003efd0a9966/JB_WORK_INVOICE_DATAPREP.py
[INFO] 2018-10-24 08:04:06,941 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540393442515
[INFO] 2018-10-24 08:04:06,942 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/userFiles-965f666b-5193-4f57-bad5-003efd0a9966/packages.zip
[INFO] 2018-10-24 08:04:07,812 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 08:04:07,853 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 521, boot = 420, init = 100, finish = 1
[INFO] 2018-10-24 08:04:07,872 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1661 bytes result sent to driver
[INFO] 2018-10-24 08:04:07,887 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 1034 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 08:04:07,894 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 08:04:07,905 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340) finished in 1.196 s
[INFO] 2018-10-24 08:04:07,911 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:340, took 1.265612 s
[INFO] 2018-10-24 08:04:07,982 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341
[INFO] 2018-10-24 08:04:07,984 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) with 1 output partitions
[INFO] 2018-10-24 08:04:07,984 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341)
[INFO] 2018-10-24 08:04:07,985 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 08:04:07,985 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 08:04:07,985 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341), which has no missing parents
[INFO] 2018-10-24 08:04:07,988 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 08:04:07,990 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 08:04:07,992 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:16592 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 08:04:07,994 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 08:04:07,994 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 08:04:07,995 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 08:04:07,996 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 08:04:07,997 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 08:04:08,343 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 08:04:08,349 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 63, boot = -423, init = 486, finish = 0
[INFO] 2018-10-24 08:04:08,351 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1663 bytes result sent to driver
[INFO] 2018-10-24 08:04:08,355 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 358 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 08:04:08,355 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 08:04:08,358 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341) finished in 0.371 s
[INFO] 2018-10-24 08:04:08,359 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:341, took 0.376553 s
[INFO] 2018-10-24 08:11:30,652 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 08:11:30,665 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 08:11:30,686 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 08:11:30,707 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 08:11:30,707 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 08:11:30,708 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 08:11:30,713 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 08:11:30,723 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 08:11:30,724 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 08:11:30,726 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1
[INFO] 2018-10-24 08:11:30,727 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-bd9a1382-4870-4f85-ba3f-3f599c3357f2
[INFO] 2018-10-24 08:11:30,727 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-11cb63e9-7419-4939-9ff6-d1f05a34adc1/pyspark-865c3384-2c11-4955-ace4-1d3ea5474d8d
[WARN] 2018-10-24 22:43:43,931 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 22:43:44,385 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 22:43:44,386 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-2ed906cc-e5dc-48bf-b606-cfedb81d5e25
[WARN] 2018-10-24 22:43:53,465 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 22:43:54,221 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 22:43:54,248 org.apache.spark.SparkContext logInfo - Submitted application: JB_UPD_WORK_BOOKINGS
[INFO] 2018-10-24 22:43:54,418 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 22:43:54,419 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 22:43:54,419 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 22:43:54,419 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 22:43:54,429 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 22:43:54,704 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 27341.
[INFO] 2018-10-24 22:43:54,738 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 22:43:54,764 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 22:43:54,768 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 22:43:54,768 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 22:43:54,781 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-31bb1d7a-e3eb-4b06-9055-1f9f38978147
[INFO] 2018-10-24 22:43:54,803 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 22:43:54,821 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 22:43:55,080 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 22:43:55,145 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 22:43:55,255 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540446235254
[INFO] 2018-10-24 22:43:55,257 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-308e8532-21b2-4438-9e1d-37afc3ce6622/userFiles-fba0ed6c-c624-4924-b08a-2a0bcd0d0124/etl_config.json
[INFO] 2018-10-24 22:43:55,273 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_UPD_BOOKINGS.py at file:/home/spark/EBI_Project/jobs/SCH/JB_UPD_BOOKINGS.py with timestamp 1540446235273
[INFO] 2018-10-24 22:43:55,274 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_UPD_BOOKINGS.py to /tmp/spark-308e8532-21b2-4438-9e1d-37afc3ce6622/userFiles-fba0ed6c-c624-4924-b08a-2a0bcd0d0124/JB_UPD_BOOKINGS.py
[INFO] 2018-10-24 22:43:55,278 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540446235278
[INFO] 2018-10-24 22:43:55,278 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-308e8532-21b2-4438-9e1d-37afc3ce6622/userFiles-fba0ed6c-c624-4924-b08a-2a0bcd0d0124/packages.zip
[INFO] 2018-10-24 22:43:55,360 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 22:43:55,387 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 17383.
[INFO] 2018-10-24 22:43:55,388 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:17383
[INFO] 2018-10-24 22:43:55,390 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 22:43:55,428 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 17383, None)
[INFO] 2018-10-24 22:43:55,448 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:17383 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 17383, None)
[INFO] 2018-10-24 22:43:55,452 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 17383, None)
[INFO] 2018-10-24 22:43:55,453 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 17383, None)
[INFO] 2018-10-24 22:43:55,746 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 22:43:55,747 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 22:43:56,266 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 22:45:52,525 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 22:45:52,538 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 22:45:52,557 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 22:45:52,572 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 22:45:52,572 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 22:45:52,575 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 22:45:52,581 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 22:45:52,601 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 22:45:52,602 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 22:45:52,603 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-308e8532-21b2-4438-9e1d-37afc3ce6622/pyspark-6409788f-0507-40fc-bb1b-dd38bea3e19f
[INFO] 2018-10-24 22:45:52,604 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-308e8532-21b2-4438-9e1d-37afc3ce6622
[INFO] 2018-10-24 22:45:52,604 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-12898377-82fe-47a9-925d-053fe737eb9a
[WARN] 2018-10-24 23:22:41,959 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:22:42,821 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:22:42,849 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:22:43,012 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:22:43,013 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:22:43,013 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:22:43,014 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:22:43,014 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:22:43,226 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 35808.
[INFO] 2018-10-24 23:22:43,254 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:22:43,273 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:22:43,276 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:22:43,277 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:22:43,286 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-caf73c81-b096-43fe-a6e3-5a6fa99b5279
[INFO] 2018-10-24 23:22:43,304 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:22:43,317 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:22:43,500 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:22:43,552 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:22:43,644 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540448563644
[INFO] 2018-10-24 23:22:43,646 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-26f41b20-d226-4b57-bfa3-1e70bfbba332/userFiles-79cb2eb4-fe53-44a2-8ebb-60d1c39f31a9/etl_config.json
[INFO] 2018-10-24 23:22:43,662 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540448563661
[INFO] 2018-10-24 23:22:43,662 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-26f41b20-d226-4b57-bfa3-1e70bfbba332/userFiles-79cb2eb4-fe53-44a2-8ebb-60d1c39f31a9/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:22:43,667 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540448563667
[INFO] 2018-10-24 23:22:43,668 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-26f41b20-d226-4b57-bfa3-1e70bfbba332/userFiles-79cb2eb4-fe53-44a2-8ebb-60d1c39f31a9/packages.zip
[INFO] 2018-10-24 23:22:43,737 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:22:43,768 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33860.
[INFO] 2018-10-24 23:22:43,769 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:33860
[INFO] 2018-10-24 23:22:43,772 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:22:43,806 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 33860, None)
[INFO] 2018-10-24 23:22:43,813 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:33860 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 33860, None)
[INFO] 2018-10-24 23:22:43,817 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 33860, None)
[INFO] 2018-10-24 23:22:43,818 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 33860, None)
[INFO] 2018-10-24 23:22:44,122 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:22:44,123 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:22:44,619 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:22:44,659 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:22:44,673 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:22:44,684 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:22:44,694 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:22:44,695 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:22:44,702 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:22:44,706 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:22:44,720 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:22:44,721 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:22:44,722 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-0e1389b3-7801-4791-9179-cc8b06d8c1a1
[INFO] 2018-10-24 23:22:44,722 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-26f41b20-d226-4b57-bfa3-1e70bfbba332/pyspark-7c3212e6-d495-4839-9882-15024ab1645b
[INFO] 2018-10-24 23:22:44,723 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-26f41b20-d226-4b57-bfa3-1e70bfbba332
[WARN] 2018-10-24 23:23:17,922 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:23:18,711 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:23:18,738 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:23:18,898 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:23:18,899 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:23:18,899 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:23:18,899 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:23:18,900 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:23:19,150 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 26652.
[INFO] 2018-10-24 23:23:19,180 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:23:19,202 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:23:19,205 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:23:19,206 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:23:19,215 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-0c945b23-8803-43a3-99bd-a56dc7aa1369
[INFO] 2018-10-24 23:23:19,234 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:23:19,249 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:23:19,446 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:23:19,500 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:23:19,597 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540448599596
[INFO] 2018-10-24 23:23:19,601 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/userFiles-4843dd7c-2f14-48c9-8e6d-0952f48d8c85/etl_config.json
[INFO] 2018-10-24 23:23:19,625 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540448599625
[INFO] 2018-10-24 23:23:19,626 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/userFiles-4843dd7c-2f14-48c9-8e6d-0952f48d8c85/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:23:19,632 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540448599631
[INFO] 2018-10-24 23:23:19,632 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/userFiles-4843dd7c-2f14-48c9-8e6d-0952f48d8c85/packages.zip
[INFO] 2018-10-24 23:23:19,699 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:23:19,722 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 10616.
[INFO] 2018-10-24 23:23:19,723 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:10616
[INFO] 2018-10-24 23:23:19,725 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:23:19,757 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 10616, None)
[INFO] 2018-10-24 23:23:19,762 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:10616 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 10616, None)
[INFO] 2018-10-24 23:23:19,765 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 10616, None)
[INFO] 2018-10-24 23:23:19,766 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 10616, None)
[INFO] 2018-10-24 23:23:20,020 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:23:20,021 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:23:20,518 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:23:23,533 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 202.834433 ms
[INFO] 2018-10-24 23:23:23,680 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:23:23,704 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:23:23,704 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:23:23,705 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:23:23,707 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:23:23,742 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:23:23,817 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:23:23,850 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:23:23,855 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:10616 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:23:23,858 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:23:23,873 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:23:23,875 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:23:23,928 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:23:23,942 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:23:23,949 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540448599625
[INFO] 2018-10-24 23:23:23,981 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/userFiles-4843dd7c-2f14-48c9-8e6d-0952f48d8c85/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:23:23,987 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540448599596
[INFO] 2018-10-24 23:23:23,988 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/userFiles-4843dd7c-2f14-48c9-8e6d-0952f48d8c85/etl_config.json
[INFO] 2018-10-24 23:23:23,994 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540448599631
[INFO] 2018-10-24 23:23:23,996 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/userFiles-4843dd7c-2f14-48c9-8e6d-0952f48d8c85/packages.zip
[INFO] 2018-10-24 23:23:24,798 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:23:24,838 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 461, boot = 361, init = 99, finish = 1
[INFO] 2018-10-24 23:23:24,860 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:23:24,878 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 962 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:23:24,882 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:23:24,894 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 1.128 s
[INFO] 2018-10-24 23:23:24,901 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.220281 s
[INFO] 2018-10-24 23:23:25,265 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:23:25,276 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:23:25,291 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:23:25,318 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:23:25,318 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:23:25,330 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:23:25,343 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:23:25,369 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:23:25,370 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:23:25,371 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da
[INFO] 2018-10-24 23:23:25,372 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d084a99e-f894-4425-8345-1ecc404820da/pyspark-1473925d-2ede-4d6c-b86d-b815b7bf9e9e
[INFO] 2018-10-24 23:23:25,372 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-fdafe9ad-cc0e-48e1-b0a5-c1cc714ef0f4
[WARN] 2018-10-24 23:29:11,915 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:29:12,698 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:29:12,721 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:29:12,887 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:29:12,887 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:29:12,888 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:29:12,888 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:29:12,888 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:29:13,099 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 31511.
[INFO] 2018-10-24 23:29:13,125 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:29:13,145 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:29:13,148 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:29:13,149 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:29:13,159 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-0f6f3c21-6b07-42e3-9dad-36f5a63bff5b
[INFO] 2018-10-24 23:29:13,177 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:29:13,191 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:29:13,383 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:29:13,436 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:29:13,554 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540448953554
[INFO] 2018-10-24 23:29:13,556 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/userFiles-06f38b39-01e3-437d-a046-5728cdc30cdd/etl_config.json
[INFO] 2018-10-24 23:29:13,569 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540448953569
[INFO] 2018-10-24 23:29:13,570 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/userFiles-06f38b39-01e3-437d-a046-5728cdc30cdd/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:29:13,574 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540448953574
[INFO] 2018-10-24 23:29:13,575 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/userFiles-06f38b39-01e3-437d-a046-5728cdc30cdd/packages.zip
[INFO] 2018-10-24 23:29:13,640 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:29:13,665 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 13400.
[INFO] 2018-10-24 23:29:13,666 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:13400
[INFO] 2018-10-24 23:29:13,668 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:29:13,698 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 13400, None)
[INFO] 2018-10-24 23:29:13,704 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:13400 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 13400, None)
[INFO] 2018-10-24 23:29:13,708 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 13400, None)
[INFO] 2018-10-24 23:29:13,708 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 13400, None)
[INFO] 2018-10-24 23:29:13,954 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:29:13,955 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:29:14,441 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:29:17,554 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 208.286532 ms
[INFO] 2018-10-24 23:29:17,707 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:29:17,731 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:29:17,732 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:29:17,733 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:29:17,735 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:29:17,742 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:29:17,811 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:29:17,849 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:29:17,852 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:13400 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:29:17,855 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:29:17,876 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:29:17,878 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:29:17,926 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:29:17,945 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:29:17,949 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540448953569
[INFO] 2018-10-24 23:29:17,980 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/userFiles-06f38b39-01e3-437d-a046-5728cdc30cdd/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:29:17,983 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540448953554
[INFO] 2018-10-24 23:29:17,984 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/userFiles-06f38b39-01e3-437d-a046-5728cdc30cdd/etl_config.json
[INFO] 2018-10-24 23:29:17,991 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540448953574
[INFO] 2018-10-24 23:29:17,992 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/userFiles-06f38b39-01e3-437d-a046-5728cdc30cdd/packages.zip
[INFO] 2018-10-24 23:29:18,790 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:29:18,829 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 483, boot = 368, init = 115, finish = 0
[INFO] 2018-10-24 23:29:18,853 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1706 bytes result sent to driver
[INFO] 2018-10-24 23:29:18,865 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 951 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:29:18,869 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:29:18,880 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 1.118 s
[INFO] 2018-10-24 23:29:18,885 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.177299 s
[INFO] 2018-10-24 23:29:19,318 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:29:19,332 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:29:19,349 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:29:19,359 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:29:19,360 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:29:19,373 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:29:19,376 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:29:19,384 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:29:19,385 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:29:19,387 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47
[INFO] 2018-10-24 23:29:19,387 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-37bcd758-f568-4821-8f31-7f134c00e2cf
[INFO] 2018-10-24 23:29:19,388 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-d9d6d5ce-b0fd-4261-8559-21e6a509fc47/pyspark-6f2b38fa-da29-4f4a-bc9c-39b2728befc8
[WARN] 2018-10-24 23:30:56,498 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:30:57,264 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:30:57,289 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:30:57,422 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:30:57,422 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:30:57,422 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:30:57,423 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:30:57,423 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:30:57,622 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 26723.
[INFO] 2018-10-24 23:30:57,647 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:30:57,666 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:30:57,668 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:30:57,669 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:30:57,677 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-d38d7750-7beb-4e3e-8460-90c81d00e95a
[INFO] 2018-10-24 23:30:57,695 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:30:57,707 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:30:57,877 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:30:57,934 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:30:58,021 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449058020
[INFO] 2018-10-24 23:30:58,023 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/userFiles-2bb2e001-d918-4ab6-90c0-12cf43c119d2/etl_config.json
[INFO] 2018-10-24 23:30:58,036 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449058036
[INFO] 2018-10-24 23:30:58,037 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/userFiles-2bb2e001-d918-4ab6-90c0-12cf43c119d2/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:30:58,041 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449058040
[INFO] 2018-10-24 23:30:58,041 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/userFiles-2bb2e001-d918-4ab6-90c0-12cf43c119d2/packages.zip
[INFO] 2018-10-24 23:30:58,110 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:30:58,136 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 14491.
[INFO] 2018-10-24 23:30:58,137 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:14491
[INFO] 2018-10-24 23:30:58,139 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:30:58,172 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 14491, None)
[INFO] 2018-10-24 23:30:58,179 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:14491 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 14491, None)
[INFO] 2018-10-24 23:30:58,184 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 14491, None)
[INFO] 2018-10-24 23:30:58,184 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 14491, None)
[INFO] 2018-10-24 23:30:58,460 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:30:58,461 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:30:58,998 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:31:02,161 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 213.82085 ms
[INFO] 2018-10-24 23:31:02,313 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:31:02,339 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:31:02,340 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:31:02,340 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:31:02,342 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:31:02,350 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:31:02,416 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:31:02,449 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:31:02,452 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:14491 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:31:02,456 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:31:02,469 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:31:02,470 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:31:02,517 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:31:02,529 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:31:02,533 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449058036
[INFO] 2018-10-24 23:31:02,566 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/userFiles-2bb2e001-d918-4ab6-90c0-12cf43c119d2/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:31:02,570 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449058020
[INFO] 2018-10-24 23:31:02,571 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/userFiles-2bb2e001-d918-4ab6-90c0-12cf43c119d2/etl_config.json
[INFO] 2018-10-24 23:31:02,576 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449058040
[INFO] 2018-10-24 23:31:02,578 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/userFiles-2bb2e001-d918-4ab6-90c0-12cf43c119d2/packages.zip
[INFO] 2018-10-24 23:31:03,379 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:31:03,411 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 450, boot = 366, init = 83, finish = 1
[INFO] 2018-10-24 23:31:03,433 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:31:03,444 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 939 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:31:03,448 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:31:03,460 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 1.091 s
[INFO] 2018-10-24 23:31:03,465 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.151710 s
[INFO] 2018-10-24 23:31:03,877 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:31:03,890 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:31:03,905 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:31:03,914 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:31:03,915 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:31:03,925 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:31:03,928 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:31:03,942 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:31:03,942 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:31:03,943 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-be39add7-8c9f-4a9e-97cf-7ee945bc6454
[INFO] 2018-10-24 23:31:03,944 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b
[INFO] 2018-10-24 23:31:03,944 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-4638040e-3e61-4d03-b1a6-1632296a833b/pyspark-0fcb228b-5abe-4a10-aad4-787130a8b6a8
[WARN] 2018-10-24 23:32:30,450 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:32:31,263 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:32:31,289 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:32:31,456 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:32:31,457 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:32:31,457 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:32:31,458 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:32:31,458 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:32:31,684 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 31436.
[INFO] 2018-10-24 23:32:31,708 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:32:31,727 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:32:31,730 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:32:31,730 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:32:31,739 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-4f7f193c-1890-4861-b9a0-c7c9fba4818a
[INFO] 2018-10-24 23:32:31,755 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:32:31,768 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:32:31,937 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:32:31,985 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:32:32,072 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449152072
[INFO] 2018-10-24 23:32:32,074 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/userFiles-a41ec959-88c3-464e-97e2-cb8dabffc539/etl_config.json
[INFO] 2018-10-24 23:32:32,088 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449152088
[INFO] 2018-10-24 23:32:32,089 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/userFiles-a41ec959-88c3-464e-97e2-cb8dabffc539/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:32:32,093 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449152093
[INFO] 2018-10-24 23:32:32,093 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/userFiles-a41ec959-88c3-464e-97e2-cb8dabffc539/packages.zip
[INFO] 2018-10-24 23:32:32,149 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:32:32,172 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31650.
[INFO] 2018-10-24 23:32:32,174 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:31650
[INFO] 2018-10-24 23:32:32,175 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:32:32,205 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 31650, None)
[INFO] 2018-10-24 23:32:32,210 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:31650 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 31650, None)
[INFO] 2018-10-24 23:32:32,213 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 31650, None)
[INFO] 2018-10-24 23:32:32,214 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 31650, None)
[INFO] 2018-10-24 23:32:32,473 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:32:32,474 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:32:33,004 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:32:36,033 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 207.859624 ms
[INFO] 2018-10-24 23:32:36,183 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:32:36,204 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:32:36,205 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:32:36,205 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:32:36,207 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:32:36,215 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:32:36,290 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:32:36,330 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:32:36,333 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:31650 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:32:36,336 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:32:36,349 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:32:36,350 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:32:36,398 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:32:36,410 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:32:36,415 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449152088
[INFO] 2018-10-24 23:32:36,445 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/userFiles-a41ec959-88c3-464e-97e2-cb8dabffc539/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:32:36,450 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449152072
[INFO] 2018-10-24 23:32:36,451 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/userFiles-a41ec959-88c3-464e-97e2-cb8dabffc539/etl_config.json
[INFO] 2018-10-24 23:32:36,456 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449152093
[INFO] 2018-10-24 23:32:36,456 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/userFiles-a41ec959-88c3-464e-97e2-cb8dabffc539/packages.zip
[INFO] 2018-10-24 23:32:37,214 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:32:37,252 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 451, boot = 364, init = 86, finish = 1
[INFO] 2018-10-24 23:32:37,271 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:32:37,290 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 902 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:32:37,294 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:32:37,309 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 1.072 s
[INFO] 2018-10-24 23:32:37,314 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.130322 s
[INFO] 2018-10-24 23:32:37,655 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:32:37,669 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:32:37,688 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:32:37,699 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:32:37,700 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:32:37,707 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:32:37,710 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:32:37,719 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:32:37,720 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:32:37,721 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4
[INFO] 2018-10-24 23:32:37,721 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-ec8b3be1-96a3-4daf-ad2c-a88f75cfad4a
[INFO] 2018-10-24 23:32:37,722 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-e6146b50-6e7a-4f7a-8ad3-39cf43f08fd4/pyspark-f4c52e93-c514-4901-9c3c-5267fc96a861
[WARN] 2018-10-24 23:35:30,189 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:35:30,973 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:35:30,999 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:35:31,162 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:35:31,162 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:35:31,163 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:35:31,163 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:35:31,163 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:35:31,365 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 36797.
[INFO] 2018-10-24 23:35:31,392 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:35:31,410 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:35:31,413 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:35:31,414 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:35:31,422 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-853437fc-1ce0-45a2-9849-636a439032f9
[INFO] 2018-10-24 23:35:31,439 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:35:31,452 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:35:31,620 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:35:31,673 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:35:31,763 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449331762
[INFO] 2018-10-24 23:35:31,765 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/userFiles-9cf5ad94-289f-4b5a-b54c-193fbb367adf/etl_config.json
[INFO] 2018-10-24 23:35:31,779 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449331779
[INFO] 2018-10-24 23:35:31,780 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/userFiles-9cf5ad94-289f-4b5a-b54c-193fbb367adf/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:35:31,785 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449331785
[INFO] 2018-10-24 23:35:31,786 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/userFiles-9cf5ad94-289f-4b5a-b54c-193fbb367adf/packages.zip
[INFO] 2018-10-24 23:35:31,856 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:35:31,882 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12665.
[INFO] 2018-10-24 23:35:31,883 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:12665
[INFO] 2018-10-24 23:35:31,885 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:35:31,918 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 12665, None)
[INFO] 2018-10-24 23:35:31,925 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:12665 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 12665, None)
[INFO] 2018-10-24 23:35:31,929 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 12665, None)
[INFO] 2018-10-24 23:35:31,930 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 12665, None)
[INFO] 2018-10-24 23:35:32,188 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:35:32,189 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:35:32,718 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:35:35,728 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 197.302684 ms
[INFO] 2018-10-24 23:35:35,878 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:35:35,900 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:35:35,900 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:35:35,901 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:35:35,903 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:35:35,911 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:35:35,989 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:35:36,025 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:35:36,029 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:12665 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:35:36,031 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:35:36,049 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:35:36,050 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:35:36,094 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:35:36,106 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:35:36,111 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449331779
[INFO] 2018-10-24 23:35:36,142 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/userFiles-9cf5ad94-289f-4b5a-b54c-193fbb367adf/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:35:36,148 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449331762
[INFO] 2018-10-24 23:35:36,149 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/userFiles-9cf5ad94-289f-4b5a-b54c-193fbb367adf/etl_config.json
[INFO] 2018-10-24 23:35:36,155 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449331785
[INFO] 2018-10-24 23:35:36,155 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/userFiles-9cf5ad94-289f-4b5a-b54c-193fbb367adf/packages.zip
[INFO] 2018-10-24 23:35:36,967 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:35:37,006 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 502, boot = 394, init = 108, finish = 0
[INFO] 2018-10-24 23:35:37,027 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:35:37,044 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 962 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:35:37,048 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:35:37,062 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 1.129 s
[INFO] 2018-10-24 23:35:37,068 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.189821 s
[INFO] 2018-10-24 23:35:37,458 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:35:37,470 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:35:37,489 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:35:37,504 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:35:37,505 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:35:37,519 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:35:37,524 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:35:37,547 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:35:37,548 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:35:37,550 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5/pyspark-3a9e2dce-5a38-4c42-84b8-8ff5c57bf80a
[INFO] 2018-10-24 23:35:37,551 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-be9247fe-87bd-4924-abc7-0424916039d5
[INFO] 2018-10-24 23:35:37,551 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-7c7b3c76-8773-4315-bd96-7970870a0b13
[WARN] 2018-10-24 23:37:10,468 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:37:11,260 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:37:11,286 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:37:11,473 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:37:11,473 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:37:11,474 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:37:11,474 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:37:11,474 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:37:11,673 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 12825.
[INFO] 2018-10-24 23:37:11,699 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:37:11,719 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:37:11,721 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:37:11,722 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:37:11,731 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-277b6582-dfd4-4775-92d1-756aaf2c9096
[INFO] 2018-10-24 23:37:11,748 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:37:11,762 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:37:11,942 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:37:12,001 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:37:12,117 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449432116
[INFO] 2018-10-24 23:37:12,119 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/userFiles-14cf4369-be22-4c89-b879-4fa788d59ccf/etl_config.json
[INFO] 2018-10-24 23:37:12,134 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449432134
[INFO] 2018-10-24 23:37:12,135 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/userFiles-14cf4369-be22-4c89-b879-4fa788d59ccf/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:37:12,140 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449432140
[INFO] 2018-10-24 23:37:12,140 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/userFiles-14cf4369-be22-4c89-b879-4fa788d59ccf/packages.zip
[INFO] 2018-10-24 23:37:12,209 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:37:12,237 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 27568.
[INFO] 2018-10-24 23:37:12,238 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:27568
[INFO] 2018-10-24 23:37:12,240 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:37:12,273 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 27568, None)
[INFO] 2018-10-24 23:37:12,280 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:27568 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 27568, None)
[INFO] 2018-10-24 23:37:12,285 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 27568, None)
[INFO] 2018-10-24 23:37:12,286 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 27568, None)
[INFO] 2018-10-24 23:37:12,535 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:37:12,536 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:37:13,094 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:37:16,024 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 209.907674 ms
[INFO] 2018-10-24 23:37:16,196 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:37:16,216 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:37:16,216 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:37:16,217 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:37:16,218 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:37:16,239 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:37:16,308 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:37:16,345 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:37:16,349 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:27568 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:37:16,352 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:37:16,368 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:37:16,369 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:37:16,420 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:37:16,435 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:37:16,442 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449432134
[INFO] 2018-10-24 23:37:16,471 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/userFiles-14cf4369-be22-4c89-b879-4fa788d59ccf/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:37:16,477 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449432116
[INFO] 2018-10-24 23:37:16,478 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/userFiles-14cf4369-be22-4c89-b879-4fa788d59ccf/etl_config.json
[INFO] 2018-10-24 23:37:16,483 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449432140
[INFO] 2018-10-24 23:37:16,485 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/userFiles-14cf4369-be22-4c89-b879-4fa788d59ccf/packages.zip
[INFO] 2018-10-24 23:37:17,234 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:37:17,273 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 430, boot = 364, init = 65, finish = 1
[INFO] 2018-10-24 23:37:17,292 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:37:17,311 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 903 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:37:17,316 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:37:17,329 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 1.068 s
[INFO] 2018-10-24 23:37:17,337 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.140478 s
[INFO] 2018-10-24 23:37:17,541 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:37:17,551 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:37:17,566 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:37:17,577 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:37:17,578 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:37:17,587 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:37:17,591 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:37:17,598 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:37:17,599 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:37:17,601 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-6e9cbd74-e160-43db-acb7-91cea778c10d
[INFO] 2018-10-24 23:37:17,601 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b
[INFO] 2018-10-24 23:37:17,601 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-0aec1e57-b02e-4ce5-97ca-57a5e56a066b/pyspark-799a16bb-67d4-415e-897d-415bf3389d74
[WARN] 2018-10-24 23:38:00,072 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:38:00,891 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:38:00,917 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:38:01,064 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:38:01,064 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:38:01,065 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:38:01,065 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:38:01,066 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:38:01,267 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 21214.
[INFO] 2018-10-24 23:38:01,293 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:38:01,312 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:38:01,315 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:38:01,315 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:38:01,324 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-85e51aa0-35f9-4de3-b302-4ec31b159a96
[INFO] 2018-10-24 23:38:01,341 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:38:01,355 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:38:01,532 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:38:01,586 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:38:01,679 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449481678
[INFO] 2018-10-24 23:38:01,680 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/userFiles-df604a77-9948-4a77-a76d-441ad9491072/etl_config.json
[INFO] 2018-10-24 23:38:01,695 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449481695
[INFO] 2018-10-24 23:38:01,695 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/userFiles-df604a77-9948-4a77-a76d-441ad9491072/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:38:01,699 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449481699
[INFO] 2018-10-24 23:38:01,699 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/userFiles-df604a77-9948-4a77-a76d-441ad9491072/packages.zip
[INFO] 2018-10-24 23:38:01,770 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:38:01,799 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 19332.
[INFO] 2018-10-24 23:38:01,800 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:19332
[INFO] 2018-10-24 23:38:01,801 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:38:01,834 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 19332, None)
[INFO] 2018-10-24 23:38:01,840 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:19332 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 19332, None)
[INFO] 2018-10-24 23:38:01,847 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 19332, None)
[INFO] 2018-10-24 23:38:01,848 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 19332, None)
[INFO] 2018-10-24 23:38:02,113 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:38:02,114 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:38:02,597 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:38:05,416 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 200.731656 ms
[INFO] 2018-10-24 23:38:05,561 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:38:05,587 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:38:05,588 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:38:05,589 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:38:05,591 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:38:05,600 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:38:05,676 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:38:05,716 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:38:05,718 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:19332 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:38:05,721 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:38:05,735 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:38:05,736 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:38:05,787 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:38:05,802 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:38:05,807 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449481695
[INFO] 2018-10-24 23:38:05,838 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/userFiles-df604a77-9948-4a77-a76d-441ad9491072/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:38:05,844 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449481678
[INFO] 2018-10-24 23:38:05,845 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/userFiles-df604a77-9948-4a77-a76d-441ad9491072/etl_config.json
[INFO] 2018-10-24 23:38:05,849 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449481699
[INFO] 2018-10-24 23:38:05,851 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/userFiles-df604a77-9948-4a77-a76d-441ad9491072/packages.zip
[INFO] 2018-10-24 23:38:06,460 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:38:06,495 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 426, boot = 365, init = 61, finish = 0
[INFO] 2018-10-24 23:38:06,516 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:38:06,533 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 757 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:38:06,537 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:38:06,548 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 0.926 s
[INFO] 2018-10-24 23:38:06,553 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 0.991510 s
[INFO] 2018-10-24 23:38:06,749 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:38:06,759 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:38:06,772 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:38:06,786 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:38:06,787 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:38:06,799 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:38:06,803 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:38:06,815 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:38:06,816 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:38:06,818 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-29b414f4-aa3f-442e-8701-95e95b049f96
[INFO] 2018-10-24 23:38:06,818 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e
[INFO] 2018-10-24 23:38:06,819 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-0467be44-46fa-49a7-bde4-64d8e08d599e/pyspark-fdf65feb-1c0c-47e3-987f-6c3e9f6d203a
[WARN] 2018-10-24 23:39:13,153 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:39:13,961 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:39:13,986 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:39:14,206 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:39:14,207 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:39:14,207 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:39:14,207 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:39:14,215 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:39:14,406 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 36874.
[INFO] 2018-10-24 23:39:14,432 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:39:14,451 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:39:14,454 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:39:14,455 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:39:14,464 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-5001e296-345e-4519-b081-312c7db8000e
[INFO] 2018-10-24 23:39:14,481 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:39:14,495 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:39:14,669 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:39:14,718 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:39:14,809 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449554809
[INFO] 2018-10-24 23:39:14,812 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/userFiles-eaa2f519-5feb-4c5b-afa2-f5fdbeba8424/etl_config.json
[INFO] 2018-10-24 23:39:14,825 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449554824
[INFO] 2018-10-24 23:39:14,825 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/userFiles-eaa2f519-5feb-4c5b-afa2-f5fdbeba8424/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:39:14,829 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449554829
[INFO] 2018-10-24 23:39:14,830 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/userFiles-eaa2f519-5feb-4c5b-afa2-f5fdbeba8424/packages.zip
[INFO] 2018-10-24 23:39:14,899 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:39:14,921 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34302.
[INFO] 2018-10-24 23:39:14,923 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:34302
[INFO] 2018-10-24 23:39:14,924 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:39:14,956 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 34302, None)
[INFO] 2018-10-24 23:39:14,961 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:34302 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 34302, None)
[INFO] 2018-10-24 23:39:14,964 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 34302, None)
[INFO] 2018-10-24 23:39:14,965 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 34302, None)
[INFO] 2018-10-24 23:39:15,227 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:39:15,228 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:39:15,781 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:39:18,671 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 212.870288 ms
[INFO] 2018-10-24 23:39:18,816 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:39:18,835 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:39:18,835 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:39:18,836 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:39:18,838 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:39:18,845 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:39:18,919 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:39:18,959 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:39:18,962 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:34302 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:39:18,964 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:39:18,977 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:39:18,979 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:39:19,028 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:39:19,040 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:39:19,048 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449554824
[INFO] 2018-10-24 23:39:19,076 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/userFiles-eaa2f519-5feb-4c5b-afa2-f5fdbeba8424/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:39:19,081 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449554809
[INFO] 2018-10-24 23:39:19,082 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/userFiles-eaa2f519-5feb-4c5b-afa2-f5fdbeba8424/etl_config.json
[INFO] 2018-10-24 23:39:19,088 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449554829
[INFO] 2018-10-24 23:39:19,089 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/userFiles-eaa2f519-5feb-4c5b-afa2-f5fdbeba8424/packages.zip
[INFO] 2018-10-24 23:39:19,701 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:39:19,741 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 421, boot = 355, init = 66, finish = 0
[INFO] 2018-10-24 23:39:19,757 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:39:19,768 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 752 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:39:19,778 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:39:19,784 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 0.914 s
[INFO] 2018-10-24 23:39:19,789 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 0.971937 s
[INFO] 2018-10-24 23:39:19,995 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:39:20,006 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:39:20,022 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:39:20,049 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:39:20,050 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:39:20,059 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:39:20,062 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:39:20,085 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:39:20,086 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:39:20,088 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-29bdf06d-33ca-4e60-95e1-755e3451be70
[INFO] 2018-10-24 23:39:20,088 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035
[INFO] 2018-10-24 23:39:20,089 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-b2e96984-578c-43d8-b0eb-0e7e3ee36035/pyspark-e5834974-31a9-4b7f-bcae-a44ba6c72b64
[WARN] 2018-10-24 23:40:34,501 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:40:35,350 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:40:35,376 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:40:35,595 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:40:35,596 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:40:35,596 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:40:35,596 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:40:35,598 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:40:35,790 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 24498.
[INFO] 2018-10-24 23:40:35,815 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:40:35,833 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:40:35,836 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:40:35,837 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:40:35,845 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-e1372fc7-2ad2-40df-830c-f0d9ff95cf09
[INFO] 2018-10-24 23:40:35,862 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:40:35,875 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:40:36,041 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:40:36,109 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:40:36,204 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449636203
[INFO] 2018-10-24 23:40:36,206 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/userFiles-c9842411-f4b5-4aec-9fc3-6cd858a5e300/etl_config.json
[INFO] 2018-10-24 23:40:36,218 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449636218
[INFO] 2018-10-24 23:40:36,219 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/userFiles-c9842411-f4b5-4aec-9fc3-6cd858a5e300/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:40:36,222 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449636222
[INFO] 2018-10-24 23:40:36,223 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/userFiles-c9842411-f4b5-4aec-9fc3-6cd858a5e300/packages.zip
[INFO] 2018-10-24 23:40:36,288 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:40:36,315 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 21085.
[INFO] 2018-10-24 23:40:36,316 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:21085
[INFO] 2018-10-24 23:40:36,318 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:40:36,353 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 21085, None)
[INFO] 2018-10-24 23:40:36,360 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:21085 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 21085, None)
[INFO] 2018-10-24 23:40:36,366 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 21085, None)
[INFO] 2018-10-24 23:40:36,366 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 21085, None)
[INFO] 2018-10-24 23:40:36,633 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:40:36,634 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:40:37,172 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:40:40,053 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 198.177642 ms
[INFO] 2018-10-24 23:40:40,202 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:40:40,229 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:40:40,230 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:40:40,230 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:40:40,232 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:40:40,248 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:40:40,314 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:40:40,342 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:40:40,345 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:21085 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:40:40,351 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:40:40,366 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:40:40,367 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:40:40,418 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:40:40,434 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:40:40,438 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449636218
[INFO] 2018-10-24 23:40:40,466 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/userFiles-c9842411-f4b5-4aec-9fc3-6cd858a5e300/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:40:40,471 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449636203
[INFO] 2018-10-24 23:40:40,472 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/userFiles-c9842411-f4b5-4aec-9fc3-6cd858a5e300/etl_config.json
[INFO] 2018-10-24 23:40:40,477 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449636222
[INFO] 2018-10-24 23:40:40,478 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/userFiles-c9842411-f4b5-4aec-9fc3-6cd858a5e300/packages.zip
[INFO] 2018-10-24 23:40:41,123 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:40:41,162 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 457, boot = 381, init = 75, finish = 1
[INFO] 2018-10-24 23:40:41,181 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:40:41,201 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 796 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:40:41,212 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:40:41,220 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 0.949 s
[INFO] 2018-10-24 23:40:41,227 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.024006 s
[WARN] 2018-10-24 23:40:44,392 org.apache.spark.util.Utils logWarning - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
[INFO] 2018-10-24 23:40:44,505 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:40:44,519 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:40:44,533 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:40:44,549 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:40:44,550 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:40:44,563 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:40:44,566 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:40:44,579 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:40:44,579 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:40:44,581 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-f579993a-f022-4da7-ad6e-f5ea6751da3f
[INFO] 2018-10-24 23:40:44,581 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1
[INFO] 2018-10-24 23:40:44,582 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-2bdf56cc-7885-4726-a5a3-3c417a030dc1/pyspark-ce3046b0-f323-4a26-a352-cbfc52ed65f1
[WARN] 2018-10-24 23:41:56,881 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:41:57,653 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:41:57,680 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:41:57,840 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:41:57,841 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:41:57,841 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:41:57,841 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:41:57,849 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:41:58,031 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 10097.
[INFO] 2018-10-24 23:41:58,055 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:41:58,073 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:41:58,076 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:41:58,077 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:41:58,086 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-71e78afd-9b60-4931-9b53-5912ee6bd194
[INFO] 2018-10-24 23:41:58,102 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:41:58,116 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:41:58,310 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:41:58,366 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:41:58,468 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449718467
[INFO] 2018-10-24 23:41:58,470 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/userFiles-e9dfb768-fbcd-4a2f-9f0a-41be0aad1b16/etl_config.json
[INFO] 2018-10-24 23:41:58,483 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449718483
[INFO] 2018-10-24 23:41:58,484 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/userFiles-e9dfb768-fbcd-4a2f-9f0a-41be0aad1b16/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:41:58,489 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540449718489
[INFO] 2018-10-24 23:41:58,490 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/userFiles-e9dfb768-fbcd-4a2f-9f0a-41be0aad1b16/packages.zip
[INFO] 2018-10-24 23:41:58,564 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:41:58,592 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 12621.
[INFO] 2018-10-24 23:41:58,593 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:12621
[INFO] 2018-10-24 23:41:58,595 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:41:58,624 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 12621, None)
[INFO] 2018-10-24 23:41:58,629 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:12621 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 12621, None)
[INFO] 2018-10-24 23:41:58,633 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 12621, None)
[INFO] 2018-10-24 23:41:58,634 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 12621, None)
[INFO] 2018-10-24 23:41:58,896 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:41:58,896 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:41:59,463 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:42:02,347 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 198.132675 ms
[INFO] 2018-10-24 23:42:02,519 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:42:02,546 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:42:02,547 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:42:02,548 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:42:02,550 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:42:02,558 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:42:02,635 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:42:02,676 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:42:02,679 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:12621 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:42:02,683 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:42:02,702 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:42:02,703 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:42:02,755 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:42:02,770 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:42:02,776 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540449718483
[INFO] 2018-10-24 23:42:02,808 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/userFiles-e9dfb768-fbcd-4a2f-9f0a-41be0aad1b16/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:42:02,814 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540449718467
[INFO] 2018-10-24 23:42:02,815 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/userFiles-e9dfb768-fbcd-4a2f-9f0a-41be0aad1b16/etl_config.json
[INFO] 2018-10-24 23:42:02,820 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540449718489
[INFO] 2018-10-24 23:42:02,821 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/userFiles-e9dfb768-fbcd-4a2f-9f0a-41be0aad1b16/packages.zip
[INFO] 2018-10-24 23:42:03,459 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:42:03,492 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 460, boot = 397, init = 62, finish = 1
[INFO] 2018-10-24 23:42:03,509 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:42:03,525 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 781 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:42:03,529 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:42:03,543 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 0.962 s
[INFO] 2018-10-24 23:42:03,550 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.030046 s
[INFO] 2018-10-24 23:42:03,784 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417
[INFO] 2018-10-24 23:42:03,785 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417) with 1 output partitions
[INFO] 2018-10-24 23:42:03,785 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417)
[INFO] 2018-10-24 23:42:03,786 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:42:03,786 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:42:03,787 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417), which has no missing parents
[INFO] 2018-10-24 23:42:03,791 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 10.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:42:03,794 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 13.2 GB)
[INFO] 2018-10-24 23:42:03,795 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:12621 (size: 5.8 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:42:03,797 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:42:03,797 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:42:03,798 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 23:42:03,799 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:42:03,801 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 23:42:04,033 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:42:04,064 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 42, boot = -521, init = 563, finish = 0
[INFO] 2018-10-24 23:42:04,067 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1661 bytes result sent to driver
[INFO] 2018-10-24 23:42:04,071 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 271 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:42:04,071 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:42:04,072 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417) finished in 0.284 s
[INFO] 2018-10-24 23:42:04,073 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:417, took 0.288687 s
[INFO] 2018-10-24 23:42:04,112 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:42:04,126 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:42:04,143 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:42:04,163 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:42:04,163 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:42:04,176 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:42:04,181 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:42:04,194 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:42:04,194 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:42:04,196 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f/pyspark-68c1bc38-e975-49f7-bde8-2f6e1f8fda08
[INFO] 2018-10-24 23:42:04,196 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-c3aec9d0-faf7-457a-b4e3-a41951dfea6f
[INFO] 2018-10-24 23:42:04,196 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-e414a9d8-8d05-499f-b774-6b861581ca06
[WARN] 2018-10-24 23:50:25,650 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:50:26,403 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:50:26,429 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:50:26,672 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:50:26,672 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:50:26,672 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:50:26,673 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:50:26,673 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:50:26,872 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 15328.
[INFO] 2018-10-24 23:50:26,898 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:50:26,917 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:50:26,920 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:50:26,921 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:50:26,929 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-2f4e375e-a3ba-4eeb-9e24-7b1aa487ba65
[INFO] 2018-10-24 23:50:26,947 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:50:26,960 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:50:27,142 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:50:27,208 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:50:27,315 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540450227314
[INFO] 2018-10-24 23:50:27,317 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/userFiles-97e0fae3-71ba-49d3-b4f9-816625795a81/etl_config.json
[INFO] 2018-10-24 23:50:27,332 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540450227332
[INFO] 2018-10-24 23:50:27,333 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/userFiles-97e0fae3-71ba-49d3-b4f9-816625795a81/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:50:27,337 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540450227337
[INFO] 2018-10-24 23:50:27,338 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/userFiles-97e0fae3-71ba-49d3-b4f9-816625795a81/packages.zip
[INFO] 2018-10-24 23:50:27,407 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:50:27,433 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31864.
[INFO] 2018-10-24 23:50:27,434 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:31864
[INFO] 2018-10-24 23:50:27,437 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:50:27,470 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 31864, None)
[INFO] 2018-10-24 23:50:27,478 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:31864 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 31864, None)
[INFO] 2018-10-24 23:50:27,483 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 31864, None)
[INFO] 2018-10-24 23:50:27,485 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 31864, None)
[INFO] 2018-10-24 23:50:27,755 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:50:27,756 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:50:28,283 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:50:31,153 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 194.128606 ms
[INFO] 2018-10-24 23:50:31,298 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:50:31,322 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:50:31,323 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:50:31,323 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:50:31,325 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:50:31,334 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:50:31,408 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:50:31,447 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:50:31,451 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:31864 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:50:31,454 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:50:31,468 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:50:31,469 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:50:31,516 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:50:31,528 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:50:31,533 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540450227332
[INFO] 2018-10-24 23:50:31,567 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/userFiles-97e0fae3-71ba-49d3-b4f9-816625795a81/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:50:31,574 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540450227314
[INFO] 2018-10-24 23:50:31,576 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/userFiles-97e0fae3-71ba-49d3-b4f9-816625795a81/etl_config.json
[INFO] 2018-10-24 23:50:31,580 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540450227337
[INFO] 2018-10-24 23:50:31,581 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/userFiles-97e0fae3-71ba-49d3-b4f9-816625795a81/packages.zip
[INFO] 2018-10-24 23:50:32,219 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:50:32,262 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 443, boot = 370, init = 72, finish = 1
[INFO] 2018-10-24 23:50:32,286 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:50:32,304 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 799 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:50:32,308 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:50:32,318 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 0.963 s
[INFO] 2018-10-24 23:50:32,323 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.024938 s
[INFO] 2018-10-24 23:50:32,524 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412
[INFO] 2018-10-24 23:50:32,525 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412) with 1 output partitions
[INFO] 2018-10-24 23:50:32,526 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412)
[INFO] 2018-10-24 23:50:32,526 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:50:32,526 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:50:32,527 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412), which has no missing parents
[INFO] 2018-10-24 23:50:32,530 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 10.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:50:32,532 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 13.2 GB)
[INFO] 2018-10-24 23:50:32,534 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:31864 (size: 5.8 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:50:32,535 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:50:32,536 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:50:32,536 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 23:50:32,538 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:50:32,539 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 23:50:32,691 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:50:32,724 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 42, boot = -410, init = 452, finish = 0
[INFO] 2018-10-24 23:50:32,728 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1661 bytes result sent to driver
[INFO] 2018-10-24 23:50:32,731 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 194 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:50:32,732 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:50:32,734 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412) finished in 0.206 s
[INFO] 2018-10-24 23:50:32,735 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412, took 0.210523 s
[INFO] 2018-10-24 23:50:32,769 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:50:32,780 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:50:32,800 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:50:32,816 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:50:32,817 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:50:32,831 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:50:32,836 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:50:32,858 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:50:32,859 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:50:32,860 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8
[INFO] 2018-10-24 23:50:32,861 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-879cefff-e05c-4a92-9bae-2c81df0f39e8/pyspark-39471b89-9689-4b44-b2d2-42cfd5428dde
[INFO] 2018-10-24 23:50:32,861 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-206f2480-3157-4bbd-8a43-94690b0b6448
[WARN] 2018-10-24 23:59:26,840 org.apache.hadoop.util.NativeCodeLoader <clinit> - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[INFO] 2018-10-24 23:59:27,609 org.apache.spark.SparkContext logInfo - Running Spark version 2.3.1
[INFO] 2018-10-24 23:59:27,635 org.apache.spark.SparkContext logInfo - Submitted application: JB_Truncate_Partition
[INFO] 2018-10-24 23:59:27,833 org.apache.spark.SecurityManager logInfo - Changing view acls to: pyspark
[INFO] 2018-10-24 23:59:27,834 org.apache.spark.SecurityManager logInfo - Changing modify acls to: pyspark
[INFO] 2018-10-24 23:59:27,834 org.apache.spark.SecurityManager logInfo - Changing view acls groups to: 
[INFO] 2018-10-24 23:59:27,834 org.apache.spark.SecurityManager logInfo - Changing modify acls groups to: 
[INFO] 2018-10-24 23:59:27,835 org.apache.spark.SecurityManager logInfo - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(pyspark); groups with view permissions: Set(); users  with modify permissions: Set(pyspark); groups with modify permissions: Set()
[INFO] 2018-10-24 23:59:28,037 org.apache.spark.util.Utils logInfo - Successfully started service 'sparkDriver' on port 21098.
[INFO] 2018-10-24 23:59:28,062 org.apache.spark.SparkEnv logInfo - Registering MapOutputTracker
[INFO] 2018-10-24 23:59:28,081 org.apache.spark.SparkEnv logInfo - Registering BlockManagerMaster
[INFO] 2018-10-24 23:59:28,083 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[INFO] 2018-10-24 23:59:28,084 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - BlockManagerMasterEndpoint up
[INFO] 2018-10-24 23:59:28,092 org.apache.spark.storage.DiskBlockManager logInfo - Created local directory at /tmp/blockmgr-f9cbcb04-bc56-4583-9f89-8f1f152ad817
[INFO] 2018-10-24 23:59:28,109 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore started with capacity 13.2 GB
[INFO] 2018-10-24 23:59:28,122 org.apache.spark.SparkEnv logInfo - Registering OutputCommitCoordinator
[INFO] 2018-10-24 23:59:28,301 org.apache.spark.util.Utils logInfo - Successfully started service 'SparkUI' on port 4040.
[INFO] 2018-10-24 23:59:28,356 org.apache.spark.ui.SparkUI logInfo - Bound SparkUI to 0.0.0.0, and started at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:59:28,458 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/configs/etl_config.json at file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540450768456
[INFO] 2018-10-24 23:59:28,461 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/configs/etl_config.json to /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/userFiles-40655cea-8d82-426c-89f7-93da7bed3390/etl_config.json
[INFO] 2018-10-24 23:59:28,474 org.apache.spark.SparkContext logInfo - Added file file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py at file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540450768474
[INFO] 2018-10-24 23:59:28,475 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py to /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/userFiles-40655cea-8d82-426c-89f7-93da7bed3390/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:59:28,479 org.apache.spark.SparkContext logInfo - Added file file:///home/spark/EBI_Project/packages.zip at file:///home/spark/EBI_Project/packages.zip with timestamp 1540450768479
[INFO] 2018-10-24 23:59:28,480 org.apache.spark.util.Utils logInfo - Copying /home/spark/EBI_Project/packages.zip to /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/userFiles-40655cea-8d82-426c-89f7-93da7bed3390/packages.zip
[INFO] 2018-10-24 23:59:28,551 org.apache.spark.executor.Executor logInfo - Starting executor ID driver on host localhost
[INFO] 2018-10-24 23:59:28,582 org.apache.spark.util.Utils logInfo - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 31405.
[INFO] 2018-10-24 23:59:28,583 org.apache.spark.network.netty.NettyBlockTransferService logInfo - Server created on vmwebietl02-dev:31405
[INFO] 2018-10-24 23:59:28,585 org.apache.spark.storage.BlockManager logInfo - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[INFO] 2018-10-24 23:59:28,618 org.apache.spark.storage.BlockManagerMaster logInfo - Registering BlockManager BlockManagerId(driver, vmwebietl02-dev, 31405, None)
[INFO] 2018-10-24 23:59:28,625 org.apache.spark.storage.BlockManagerMasterEndpoint logInfo - Registering block manager vmwebietl02-dev:31405 with 13.2 GB RAM, BlockManagerId(driver, vmwebietl02-dev, 31405, None)
[INFO] 2018-10-24 23:59:28,630 org.apache.spark.storage.BlockManagerMaster logInfo - Registered BlockManager BlockManagerId(driver, vmwebietl02-dev, 31405, None)
[INFO] 2018-10-24 23:59:28,630 org.apache.spark.storage.BlockManager logInfo - Initialized BlockManager: BlockManagerId(driver, vmwebietl02-dev, 31405, None)
[INFO] 2018-10-24 23:59:28,912 org.apache.spark.sql.internal.SharedState logInfo - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/spark/EBI_Project/spark-warehouse/').
[INFO] 2018-10-24 23:59:28,913 org.apache.spark.sql.internal.SharedState logInfo - Warehouse path is 'file:/home/spark/EBI_Project/spark-warehouse/'.
[INFO] 2018-10-24 23:59:29,425 org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef logInfo - Registered StateStoreCoordinator endpoint
[INFO] 2018-10-24 23:59:32,387 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator logInfo - Code generated in 216.411847 ms
[INFO] 2018-10-24 23:59:32,535 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380
[INFO] 2018-10-24 23:59:32,559 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) with 1 output partitions
[INFO] 2018-10-24 23:59:32,560 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380)
[INFO] 2018-10-24 23:59:32,561 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:59:32,562 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:59:32,570 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380), which has no missing parents
[INFO] 2018-10-24 23:59:32,638 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0 stored as values in memory (estimated size 11.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:59:32,676 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 13.2 GB)
[INFO] 2018-10-24 23:59:32,680 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_0_piece0 in memory on vmwebietl02-dev:31405 (size: 6.2 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:59:32,683 org.apache.spark.SparkContext logInfo - Created broadcast 0 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:59:32,705 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 0 (PythonRDD[4] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:59:32,707 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 0.0 with 1 tasks
[INFO] 2018-10-24 23:59:32,764 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:59:32,779 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 0.0 (TID 0)
[INFO] 2018-10-24 23:59:32,787 org.apache.spark.executor.Executor logInfo - Fetching file:/home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py with timestamp 1540450768474
[INFO] 2018-10-24 23:59:32,819 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/jobs/SCH/JB_Truncate_Partition.py has been previously copied to /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/userFiles-40655cea-8d82-426c-89f7-93da7bed3390/JB_Truncate_Partition.py
[INFO] 2018-10-24 23:59:32,825 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/configs/etl_config.json with timestamp 1540450768456
[INFO] 2018-10-24 23:59:32,826 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/configs/etl_config.json has been previously copied to /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/userFiles-40655cea-8d82-426c-89f7-93da7bed3390/etl_config.json
[INFO] 2018-10-24 23:59:32,832 org.apache.spark.executor.Executor logInfo - Fetching file:///home/spark/EBI_Project/packages.zip with timestamp 1540450768479
[INFO] 2018-10-24 23:59:32,834 org.apache.spark.util.Utils logInfo - /home/spark/EBI_Project/packages.zip has been previously copied to /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/userFiles-40655cea-8d82-426c-89f7-93da7bed3390/packages.zip
[INFO] 2018-10-24 23:59:33,457 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:59:33,493 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 425, boot = 362, init = 62, finish = 1
[INFO] 2018-10-24 23:59:33,517 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 0.0 (TID 0). 1663 bytes result sent to driver
[INFO] 2018-10-24 23:59:33,535 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 0.0 (TID 0) in 782 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:59:33,540 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 0.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:59:33,550 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 0 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380) finished in 0.960 s
[INFO] 2018-10-24 23:59:33,556 org.apache.spark.scheduler.DAGScheduler logInfo - Job 0 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:380, took 1.020074 s
[INFO] 2018-10-24 23:59:33,764 org.apache.spark.SparkContext logInfo - Starting job: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412
[INFO] 2018-10-24 23:59:33,767 org.apache.spark.scheduler.DAGScheduler logInfo - Got job 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412) with 1 output partitions
[INFO] 2018-10-24 23:59:33,767 org.apache.spark.scheduler.DAGScheduler logInfo - Final stage: ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412)
[INFO] 2018-10-24 23:59:33,767 org.apache.spark.scheduler.DAGScheduler logInfo - Parents of final stage: List()
[INFO] 2018-10-24 23:59:33,768 org.apache.spark.scheduler.DAGScheduler logInfo - Missing parents: List()
[INFO] 2018-10-24 23:59:33,769 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412), which has no missing parents
[INFO] 2018-10-24 23:59:33,774 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1 stored as values in memory (estimated size 10.3 KB, free 13.2 GB)
[INFO] 2018-10-24 23:59:33,777 org.apache.spark.storage.memory.MemoryStore logInfo - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 13.2 GB)
[INFO] 2018-10-24 23:59:33,778 org.apache.spark.storage.BlockManagerInfo logInfo - Added broadcast_1_piece0 in memory on vmwebietl02-dev:31405 (size: 5.8 KB, free: 13.2 GB)
[INFO] 2018-10-24 23:59:33,780 org.apache.spark.SparkContext logInfo - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
[INFO] 2018-10-24 23:59:33,781 org.apache.spark.scheduler.DAGScheduler logInfo - Submitting 1 missing tasks from ResultStage 1 (PythonRDD[9] at collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412) (first 15 tasks are for partitions Vector(0))
[INFO] 2018-10-24 23:59:33,781 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Adding task set 1.0 with 1 tasks
[INFO] 2018-10-24 23:59:33,782 org.apache.spark.scheduler.TaskSetManager logInfo - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7677 bytes)
[INFO] 2018-10-24 23:59:33,783 org.apache.spark.executor.Executor logInfo - Running task 0.0 in stage 1.0 (TID 1)
[INFO] 2018-10-24 23:59:33,929 org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD logInfo - closed connection
[INFO] 2018-10-24 23:59:33,955 org.apache.spark.api.python.PythonRunner logInfo - Times: total = 42, boot = -412, init = 454, finish = 0
[INFO] 2018-10-24 23:59:33,958 org.apache.spark.executor.Executor logInfo - Finished task 0.0 in stage 1.0 (TID 1). 1661 bytes result sent to driver
[INFO] 2018-10-24 23:59:33,962 org.apache.spark.scheduler.TaskSetManager logInfo - Finished task 0.0 in stage 1.0 (TID 1) in 180 ms on localhost (executor driver) (1/1)
[INFO] 2018-10-24 23:59:33,962 org.apache.spark.scheduler.TaskSchedulerImpl logInfo - Removed TaskSet 1.0, whose tasks have all completed, from pool 
[INFO] 2018-10-24 23:59:33,964 org.apache.spark.scheduler.DAGScheduler logInfo - ResultStage 1 (collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412) finished in 0.192 s
[INFO] 2018-10-24 23:59:33,964 org.apache.spark.scheduler.DAGScheduler logInfo - Job 1 finished: collect at /home/spark/EBI_Project/packages.zip/dependencies/EbiReadWrite.py:412, took 0.199196 s
[INFO] 2018-10-24 23:59:34,002 org.apache.spark.SparkContext logInfo - Invoking stop() from shutdown hook
[INFO] 2018-10-24 23:59:34,013 org.apache.spark.ui.SparkUI logInfo - Stopped Spark web UI at http://vmwebietl02-dev:4040
[INFO] 2018-10-24 23:59:34,029 org.apache.spark.MapOutputTrackerMasterEndpoint logInfo - MapOutputTrackerMasterEndpoint stopped!
[INFO] 2018-10-24 23:59:34,047 org.apache.spark.storage.memory.MemoryStore logInfo - MemoryStore cleared
[INFO] 2018-10-24 23:59:34,048 org.apache.spark.storage.BlockManager logInfo - BlockManager stopped
[INFO] 2018-10-24 23:59:34,060 org.apache.spark.storage.BlockManagerMaster logInfo - BlockManagerMaster stopped
[INFO] 2018-10-24 23:59:34,066 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint logInfo - OutputCommitCoordinator stopped!
[INFO] 2018-10-24 23:59:34,079 org.apache.spark.SparkContext logInfo - Successfully stopped SparkContext
[INFO] 2018-10-24 23:59:34,079 org.apache.spark.util.ShutdownHookManager logInfo - Shutdown hook called
[INFO] 2018-10-24 23:59:34,081 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b/pyspark-ccd36369-1696-4dab-a39f-3db59e28b3d6
[INFO] 2018-10-24 23:59:34,082 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-73e05a51-4428-4a0e-935c-e34bcc8eaa8b
[INFO] 2018-10-24 23:59:34,082 org.apache.spark.util.ShutdownHookManager logInfo - Deleting directory /tmp/spark-96cef1b1-c378-491a-8f6e-ed9841a9fc29
